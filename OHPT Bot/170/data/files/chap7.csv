ChapterâŒ˜PageâŒ˜Text
7âŒ˜0âŒ˜Chapter 7 Linear programming and reductions Many oftheproblems forwhic hwewantalgorithms areoptimization tasks: theshortest path, thecheapest spanning tree,thelongest increasing subsequence ,andsoon.Insuchcases ,we seek asolution that (1)satises certain constraints (forinstance ,thepath must useedges ofthegraph and lead fromstot,thetree must touchallnodes ,thesubsequence must be increasing); and(2)isthebest possible ,with respect tosome well-dened criterion, among all solutions that satisfy these constraints . Linear programming describes abroad class ofoptimization tasks inwhic hboth thecon- straints andtheoptimization criterion arelinear functions .Itturns outanenormous number ofproblems canbeexpressed inthisway. Given thevastness ofitstopic ,thischapter isdivided intoseveral parts ,whic hcanberead separately subject tothefollowing dependencies . DualitymatchingsFlows and Games SimplexIntroduction to linear programming and reductions 7.1 Anintroduction tolinear programming Inalinear programming problem wearegiven asetofvariables ,andwewanttoassign real values tothem soasto(1)satisfy asetoflinear equations and/or linear inequalities involving these variables and(2)maximize orminimize agiven linear objective function. 201
7âŒ˜1âŒ˜202 Algorithms Figure 7.1(a)The feasible region foralinear program. (b)Contour lines oftheobjective function:x1+6x2=cfordifferent values oftheprotc. (a) 100 200 300 400100200300400 0x2 x1(b) 100 200 300 400100200300400 0c=1500 c=1200 c=600x2 x1Optimum point Prot =$1900 7.1.1 Example: prot maximization Aboutique chocolatier hastwo products: itsagship assortment oftriangular chocolates , called Pyramide ,andthemore decadent anddeluxe Pyramide Nuit .How muchofeachshould itproduce tomaximize prots? Let'ssayitmakesx1boxes ofPyramide perday,ataprot of $1each,andx2boxes ofNuit, atamore substantial prot of$6apiece;x1andx2areunknown values that wewish todetermine .Butthisisnotall;there arealsosome constraints onx1and x2that must beaccommodated (besides theobvious one,x1;x20).First, thedaily demand forthese exclusive chocolates islimited toatmost 200boxes ofPyramide and300boxes of Nuit. Also,thecurrent workforce canproduce atotal ofatmost400boxes ofchocolate perday. What aretheoptimal levels ofproduction? Werepresent thesituation byalinear program ,asfollows . Objective function maxx1+6x2 Constraints x1200 x2300 x1+x2400 x1;x20 Alinear equation inx1andx2denes aline inthetwo-dimensional (2D) plane ,and a linear inequality designates ahalf-space ,theregion ononeside oftheline.Thus theset ofallfeasible solutions ofthis linear program, that is,thepoints (x1;x2)whic hsatisfy all constraints ,istheintersection ofvehalf-spaces .Itisaconvex polygon, shown inFigure 7.1. Wewanttond thepoint inthis polygon atwhic htheobjective functionÂ—the protÂ—is maximized. Thepoints with aprot ofcdollars lieonthelinex1+6x2=c,whic hhasaslope of1=6and isshown inFigure 7.1forselected values ofc.Ascincreases ,this Â“prot lineÂ” moves parallel toitself ,upandtotheright. Since thegoal istomaximizec,wemust move
7âŒ˜2âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 203 thelineasfarupaspossible ,while still touching thefeasible region. The optimum solution willbethevery lastfeasible point that theprot linesees andmust therefore beavertex of thepolygon, asshown inthegure .Iftheslope oftheprot linewere different, then itslast contact with thepolygon could beanentire edge rather than asingle vertex. Inthiscase,the optimum solution would notbeunique ,butthere would certainly beanoptimum vertex. Itisageneral rule oflinear programs that theoptimum isachieved atavertex ofthe feasible region. Theonly exceptions arecases inwhic hthere isnooptimum; thiscanhappen intwoways: 1.Thelinear program isinfeasible ;that is,theconstraints aresotight that itisimpossible tosatisfy allofthem. Forinstance , x1;x2: 2.The constraints aresoloose that thefeasible region isunbounded ,anditispossible to achieve arbitrarily high objective values .Forinstance , maxx1+x2 x1;x20 Solving linear programs Linear programs (LPs) canbesolved bythesimplex method ,devised byGeorge Dantzig in 1947. Weshall explain itinmore detail inSection 7.6,butbriey ,this algorithm starts ata vertex, inourcase perhaps (0;0),andrepeatedly looks foranadjacent vertex (connected by anedge ofthefeasible region) ofbetter objective value .Inthis wayitdoes hill-climbing on thevertices ofthepolygon, walking from neighbor toneighbor soastosteadily increase prot along theway.Here' sapossible trajectory . 100300 200 100 200 0Prot $1900 $0 $200$1400 Upon reaching avertex that hasnobetter neighbor ,simplex declares ittobeoptimal and halts .Why does this local test imply global optimality? Bysimple geometryÂ—think ofthe prot linepassing through thisvertex. Since allthevertex' sneighbors liebelow theline,the restofthefeasible polygon must also liebelow thisline.
7âŒ˜3âŒ˜204 Algorithms Figure 7.2Thefeasible polyhedron forathree-variable linear program. x1 x3x2 Optimum More products Encouraged byconsumer demand, thechocolatier decides tointroduce athird andeven more exclusive lineofchocolates ,called Pyramide Luxe .One boxofthese willbring inaprot of$13. Letx1;x2;x3denote thenumber ofboxes ofeachchocolate produced daily ,withx3referring to Luxe .Theoldconstraints onx1andx2persist, although thelabor restriction now extends to x3aswell: thesum ofallthree variables canbeatmost 400.What' smore ,itturns outthat Nuit andLuxe require thesame packaging machinery ,except that Luxe uses itthree times asmuch,whic himposes another constraint x2+3x3600.What arethebest possible levels ofproduction? Here istheupdated linear program. maxx1+6x2+13x3 x1200 x2300 x1+x2+x3400 x2+3x3600 x1;x2;x30
7âŒ˜4âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 205 Thespace ofsolutions isnow three-dimensional. Eachlinear equation denes a3Dplane , andeachinequality ahalf-space ononesideoftheplane .Thefeasible region isanintersection ofseven half-spaces ,apolyhedron (Figure 7.2). Looking atthegure ,canyoudecipher whic h inequality corresponds toeachface ofthepolyhedron? Aprot ofccorresponds totheplanex1+6x2+13x3=c.Ascincreases ,thisprot-plane moves parallel toitself ,further andfurther intothepositive orthant until itnolonger touches thefeasible region. The point ofnal contact istheoptimal vertex: (0;300;100),with total prot $3100 . How would thesimplex algorithm beha veonthis modied problem? Asbefore ,itwould move from vertex tovertex, along edges ofthepolyhedron, increasing prot steadily .Apossi- bletrajectory isshown inFigure 7.2,corresponding tothefollowing sequence ofvertices and prots: (0;0;0) $0!(200;0;0) $200!(200;200;0) $1400!(200;0;200) $2800!(0;300;100) $3100 Finally ,upon reaching avertex with nobetter neighbor ,itwould stop anddeclare this tobe theoptimal point. Once again bybasic geometry ,ifallthevertex' sneighbors lieononeside oftheprot-plane ,then somust theentire polyhedron. Amagic trick called duality Here iswhy youshould believe that(0;300;100),with atotal prot of$3100 ,istheoptimum: Look backatthelinear program. Add thesecond inequality tothethird, andaddtothem thefourth multiplied by4.Theresult istheinequality x1+6x2+13x33100. Doyousee? This inequality saysthat nofeasible solution (valuesx1;x2;x3satisfying the constraints) canpossibly haveaprot greater than3100.Sowemust indeed havefound the optimum! Theonly question is,where didwegetthese mysterious multipliers (0;1;1;4)for thefour inequalities? InSection 7.4we'll seethat itisalwayspossible tocome upwith suchmultipliers by solving another LP!Except that (itgets even better) wedonoteven need tosolve thisother LP,because itisinfactsointimately connected totheoriginal oneÂ—it iscalled thedual Â— that solving theoriginal LPsolves thedual aswell! But wearegetting farahead ofour story . What ifweaddafourth lineofchocolates ,orhundreds more ofthem? Then theproblem becomes high-dimensional, andhard tovisualize .Simplex continues towork inthis general setting ,although wecannolonger rely upon simple geometric intuitions foritsdescription andjustication. Wewillstudy thefull-edged simplex algorithm inSection 7.6. Inthemeantime ,wecanrestassured intheknowledge that there aremany professional, industrial-strength packages that implement simplex and take care ofallthetrickydetails likenumeric precision. Inatypical application, themain task istherefore tocorrectly express theproblem asalinear program. Thepackage then takes care oftherest. Withthisinmind, let'slook atahigh-dimensional application.
7âŒ˜5âŒ˜206 Algorithms 7.1.2 Example: production planning This time,ourcompany makes handwoven carpets ,aproduct forwhic hthedemand isex- tremely seasonal. Our analyst hasjustobtained demand estimates forallmonths ofthenext calendar year:d1;d2;:::;d12.Asfeared, they arevery uneven, ranging from 440to920. Here' saquicksnapshot ofthecompany .Wecurrently have30employees ,eachofwhom makes 20carpets permonth andgets amonthly salary of$2;000.Wehavenoinitial surplus ofcarpets . How canwehandle theuctuations indemand? There arethree ways: 1.Overtime ,butthis isexpensive since overtime payis80% more than regular pay.Also, workers canputinatmost 30% overtime . 2.Hiring andring ,butthese cost$320 and$400, respectively ,perworker . 3.Storing surplus production ,butthis costs $8percarpet permonth. Wecurrently have nostored carpets onhand, andwemust endtheyear without anycarpets stored. This rather involved problem canbeformulated andsolved asalinear program! Acrucial rst step isdening thevariables . wi=number ofworkers duringithmonth;w0=30. xi=number ofcarpets made duringithmonth. oi=number ofcarpets made byovertime inmonthi. hi;fi=number ofworkers hired andred, respectively ,atbeginning ofmonthi. si=number ofcarpets stored atendofmonthi;s0=0. Allinall,there are72variables (74ifyoucountw0ands0). Wenow write theconstraints .First, allvariables must benonnegative: wi;xi;oi;hi;fi;si0;i=1;:::;12: Thetotal number ofcarpets made permonth consists ofregular production plus overtime: xi=20wi+oi (one constraint foreachi=1;:::;12).The number ofworkers canpotentially change atthe start ofeachmonth: wi=wi1+hifi: The number ofcarpets stored attheendofeachmonth iswhat westarted with, plus the number wemade ,minus thedemand forthemonth: si=si1+xidi: And overtime islimited: oi6wi:
7âŒ˜6âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 207 Finally ,what istheobjective function? Itistominimize thetotal cost: min2000X iwi+320X ihi+400X ifi+8X isi+180X ioi; alinear function ofthevariables .Solving this linear program bysimplex should take less than asecond andwillgive ustheoptimum business strategy forourcompany . Well,almost. Theoptimum solution might turn outtobefractional ;forinstance ,itmight involve hiring 10:6workers inthemonth ofMarc h.This number would havetoberounded to either 10or11inorder tomake sense ,andtheoverall cost would then increase correspond- ingly .Inthepresent example ,most ofthevariables take onfairly large (double-digit) values , and thus rounding isunlikely toaffect things toomuch.There areother LPs,however ,in whic hrounding decisions havetobemade very carefully inorder toendupwith aninteger solution ofreasonable quality . Ingeneral, there isatension inlinear programming between theease ofobtaining frac- tional solutions and thedesirability ofinteger ones.Asweshall seeinChapter 8,nding theoptimum integer solution ofanLPisanimportant butvery hard problem, called integer linear programming . 7.1.3 Example: optimum bandwidth allocation Next weturn toaminiaturized version ofthekind ofproblem anetwork service provider might face. Suppose wearemanaging anetwork whose lines havethebandwidths shown inFig- ure7.3, and weneed toestablish three connections: between usersAandB,betweenB andC,andbetweenAandC.Eachconnection requires atleast twounits ofbandwidth, but canbeassigned more .Connection AÂ–Bpays$3perunit ofbandwidth, andconnections BÂ–C andAÂ–Cpay$2and$4,respectively . Eachconnection canberouted intwoways,along path andashort path, orbyacombina- tion: forinstance ,twounits ofbandwidth viatheshort route ,oneviathelong route .How do weroute these connections tomaximize ournetwork' srevenue? This isalinear program. Wehavevariables foreachconnection and eachpath (long or short); forexample ,xABistheshort-path bandwidth allocated totheconnection betweenA andB,andx0 ABthelong-path bandwidth forthissame connection. Wedemand that noedge' s bandwidth isexceeded andthat eachconnection gets abandwidth ofatleast 2units .
7âŒ˜7âŒ˜208 Algorithms Figure 7.3Acommunications network between three usersA;B,andC.Bandwidths are shown. a c b12 106 1311 8user A user Buser C max 3xAB+3x0 AB+2xBC+2x0 BC+4xAC+4x0 AC xAB+x0 AB+xBC+x0 BC10 [edge (b;B)] xAB+x0 AB+xAC+x0 AC12 [edge (a;A)] xBC+x0 BC+xAC+x0 AC8 [edge (c;C)] xAB+x0 BC+x0 AC6 [edge (a;b)] x0 AB+xBC+x0 AC13 [edge (b;c)] x0 AB+x0 BC+xAC11 [edge (a;c)] xAB+x0 AB2 xBC+x0 BC2 xAC+x0 AC2 xAB;x0 AB;xBC;x0 BC;xAC;x0 AC0 Even atiny example likethisoneishard tosolve onone'sown (tryit!),andyettheoptimal solution isobtained instantaneously viasimplex: xAB=0;x0 AB=7;xBC=x0 BC=1:5;xAC=0:5;x0 AC=4:5: This solution isnotintegral, butinthepresent application wedon't need ittobe,andthus no rounding isrequired. Looking backattheoriginal network, weseethat every edge exceptaÂ–c isused atfullcapacity . One cautionary observation: ourLPhasonevariable forevery possible path between the users .Inalarger network, there could easily beexponentially many suchpaths ,andtherefore
7âŒ˜8âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 209 thisparticular wayoftranslating thenetwork problem intoanLPwillnotscale well. Wewill seeacleverer andmore scalable formulation inSection 7.2. Here' saparting question foryoutoconsider .Suppose weremoved theconstraint that eachconnection should receive atleast twounits ofbandwidth. Would theoptimum change? Reductions Sometimes acomputational task issufciently general that anysubroutine foritcanalso beused tosolve avariety ofother tasks ,whic hatrst glance might seem unrelated. For instance ,wesawinChapter 6how analgorithm fornding thelongest path inadagcan, surprisingly ,also beused fornding longest increasing subsequences .Wedescribe thisphe- nomenon bysaying that thelongest increasing subsequence problem reduces tothelongest path problem inadag.Inturn, thelongest path inadagreduces totheshortest path ina dag; here' show asubroutine forthelatter canbeused tosolve theformer: function LONGESTPATH(G) negate alledge weights ofG return SHORTESTPATH(G) Let'sstep backandtake aslightly more formal view ofreductions .Ifanysubroutine for taskQcanalso beused tosolveP,wesayPreduces toQ.Often,Pissolvable byasingle calltoQ'ssubroutine ,whic hmeans anyinstancexofPcanbetransformed intoaninstance yofQsuchthatP(x)canbededuced fromQ(y): Postprocess x P(x)Q(y)Algorithm forP PreprocessforQAlgorithmy (Doyouseethat thereduction fromP=LONGESTPATHtoQ=SHORTESTPATHfollows thisschema?) Ifthepre- andpostprocessing procedures areefciently computable then this creates anefcient algorithm forPoutofanyefcient algorithm forQ! Reductions enhance thepower ofalgorithms: Once wehaveanalgorithm forproblem Q(whic hcould beshortest path, forexample) wecanuseittosolve other problems .In fact, most ofthecomputational tasks westudy inthis book areconsidered core computer science problems precisely because they arise insomany different applications ,whic his another wayofsaying that many problems reduce tothem. This isespecially true oflinear programming .
7âŒ˜9âŒ˜210 Algorithms 7.1.4 Variants oflinear programming Asevidenced inourexamples ,ageneral linear program hasmany degrees offreedom. 1.Itcanbeeither amaximization oraminimization problem. 2.Itsconstraints canbeequations and/or inequalities . 3.The variables areoften restricted tobenonnegative ,butthey canalso beunrestricted insign. Wewillnow show that these various LPoptions canallbereduced tooneanother viasimple transformations .Here' show. 1.Toturn amaximization problem into aminimization (orvice versa), just multiply the coefcients oftheobjective function by1. 2a.Toturn aninequality constraint likePn i=1aixibinto anequation, introduce anew variablesanduse nX i=1aixi+s=b s0: Thissiscalled theslackvariable fortheinequality .Asjustication, observe that a vector (x1;:::;xn)satises theoriginal inequality constraint ifandonly ifthere issome s0forwhic hitsatises thenew equality constraint. 2b.Tochange anequality constraint into inequalities iseasy: rewriteax=bastheequiva- lent pair ofconstraints axbandaxb. 3.Finally ,todeal with avariablexthat isunrestricted insign, dothefollowing: Introduce twononnegative variables ,x+;x0. Replacex,wherever itoccurs intheconstraints ortheobjective function, byx+x. This way,xcantake onany real value byappropriately adjusting thenew variables . More precisely ,anyfeasible solution totheoriginal LPinvolvingxcanbemapped toa feasible solution ofthenew LPinvolvingx+;x,andviceversa. Byapplying these transformations wecanreduce anyLP(maximization orminimization, with both inequalities andequations ,andwith both nonnegative andunrestricted variables) into anLPofamuchmore constrained kind that wecallthestandard form,inwhic hthe variables areallnonnegative ,theconstraints areallequations ,andtheobjective function is tobeminimized. Forexample ,ourrst linear program gets rewritten thus:
7âŒ˜10âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 211 maxx1+6x2 x1200 x2300 x1+x2400 x1;x20=)minx16x2 x1+s1=200 x2+s2=300 x1+x2+s3=400 x1;x2;s1;s2;s30 Theoriginal wasalso inauseful form: maximize anobjective subject tocertain inequalities . Any LPcanlikewise berecast inthisway,using thereductions given earlier . Matrix-vector notation Alinear function likex1+6x2canbewritten asthedotproduct oftwovectors c=1 6 andx=x1 x2 ; denoted cxorcTx.Similarly ,linear constraints canbecompiled into matrix-vector form: x1200 x2300 x1+x2400=)0 @10 01 111 A |{z}x1 x2 0 @200 300 4001 A |{z}: A x b Here eachrowofmatrix Acorresponds tooneconstraint: itsdotproduct withxisatmost thevalue inthecorresponding row ofb.Inother words ,iftherows ofAarethevectors a1;:::;am,then thestatement Axbisequivalent to aixbiforalli=1;:::;m. Withthese notational conveniences ,ageneric LPcanbeexpressed simply as maxcTx Axb x0: 7.2 Flows innetworks 7.2.1 Shipping oil Figure 7.4(a) shows adirected graph representing anetwork ofpipelines along whic hoilcan besent. The goal istoship asmuchoilaspossible from thesourcestothesinkt.Each pipeline hasamaximum capacity itcanhandle ,andthere arenoopportunities forstoring oil
7âŒ˜11âŒ˜212 Algorithms Figure 7.4(a)Anetwork with edge capacities .(b)Aow inthenetwork. (a) sa b cd et33 410 12 5 52 11(b) sa b cd et 52 01 02 1 4 52 1 enroute .Figure 7.4(b) shows apossible ow fromstot,whic hships 7units inall.Isthisthe best that canbedone? 7.2.2 Maximizing ow The networks wearedealing with consist ofadirected graphG=(V;E);twospecial nodes s;t2V,whic hare,respectively ,asource andsink ofG;andcapacitiesce>0ontheedges . Wewould liketosend asmuchoilaspossible fromstotwithout exceeding thecapacities ofanyoftheedges .Aparticular shipping scheme iscalled aow andconsists ofavariablefe foreachedgeeofthenetwork, satisfying thefollowing twoproperties: 1.Itdoesn't violate edge capacities: 0feceforalle2E. 2.Forallnodesuexceptsandt,theamount ofow enteringuequals theamount leaving u: X (w;u)2Efwu=X (u;z)2Efuz: Inother words ,ow isconserved . The sizeofaow isthetotal quantity sent fromstotand, bytheconservation principle , isequal tothequantity leavings: size(f)=X (s;u)2Efsu: Inshort, ourgoal istoassign values toffe:e2Egthat will satisfy asetoflinear constraints and maximize alinear objective function. But this isalinear program! The maximum-ow problem reduces tolinear programming . Forexample ,forthenetwork ofFigure 7.4theLPhas11variables ,oneperedge.Itseeks tomaximizefsa+fsb+fscsubject toatotal of27constraints: 11fornonnegativity (suchas fsa0),11forcapacity (suchasfsa3),and5forow conservation (one foreachnode of thegraph other thansandt,suchasfsc+fdc=fce).Simplex would take notime atallto correctly solve theproblem andtoconrm that, inourexample ,aow of7isinfactoptimal.
7âŒ˜12âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 213 Figure 7.5Anillustration ofthemax-ow algorithm. (a)Atoynetwork. (b)The rst path chosen. (c)Thesecond path chosen. (d)Thenal ow.(e)Wecould havechosen thispath rst. (f)Inwhic hcase,wewould havetoallow thissecond path. (a) s ba t 1111 1(b) sa t (c) s bt(d) s ba t 1111 0 (e) s ba t1 1 1(f) s ba t 11 1 7.2.3 Acloser look atthealgorithm Allweknow sofarofthesimplex algorithm isthevague geometric intuition that itkeeps making local moves onthesurface ofaconvex feasible region, successively improving the objective function until itnally reachestheoptimal solution. Once wehavestudied itin more detail (Section 7.6), wewillbeinaposition tounderstand exactly how ithandles ow LPs,whic hisuseful asasource ofinspiration fordesigning direct max-ow algorithms . Itturns outthat infactthebeha viorofsimplex hasanelementary interpretation: Start with zero ow. Repeat: choose anappropriate path fromstot,andincrease ow along theedges ofthispath asmuchaspossible . Figure 7.5(a)Â–(d) shows asmall example inwhic hsimplex halts after twoiterations .The nal ow hassize2,whic hiseasily seen tobeoptimal.
7âŒ˜13âŒ˜214 Algorithms There isjustonecomplication. What ifwehadinitially chosen adifferent path, theonein Figure 7.5(e)? This gives only oneunit ofow andyetseems toblockallother paths .Simplex gets around this problem byalso allowing paths tocancel existing ow.Inthis particular case,itwould subsequently choose thepath ofFigure 7.5(f). Edge (b;a)ofthis path isn't in theoriginal network andhastheeffect ofcanceling ow previously assigned toedge(a;b). Tosummarize ,ineachiteration simplex looks foranstpath whose edges (u;v)canbe oftwotypes: 1.(u;v)isintheoriginal network, andisnotyetatfullcapacity . 2.Thereverse edge(v;u)isintheoriginal network, andthere issome ow along it. Ifthecurrent ow isf,then intherst case,edge(u;v)canhandle uptocuvfuvadditional units ofow,and inthesecond case,uptofvuadditional units (canceling allorpart ofthe existing ow on(v;u)).These ow-increasing opportunities canbecaptured inaresidual networ kGf=(V;Ef),whic hhasexactly thetwotypes ofedges listed, with residual capacities cf: cuvfuvif(u;v)2Eandfuv<cuv fvu if(v;u)2Eandfvu>0 Thus wecanequivalently think ofsimplex aschoosing anstpath intheresidual network. Bysimulating thebeha vior ofsimplex, wegetadirect algorithm forsolving max-ow .It proceeds initerations ,eachtime explicitly constructing Gf,nding asuitablestpath in Gfbyusing ,say,alinear -time breadth-rst searc h,andhalting ifthere isnolonger anysuch path along whic how canbeincreased. Figure 7.6illustrates thealgorithm onouroilexample . 7.2.4 Acerticate ofoptimality Now foratruly remarkable fact: notonly does simplex correctly compute amaximum ow, butitalso generates ashort proof oftheoptimality ofthisow! Let'sseeanexample ofwhat thismeans .Partition thenodes oftheoilnetwork (Figure 7.4) into twogroups ,L=fs;a;bgandR=fc;d;e;tg: sa b cd et33 410 12 1 512 5L R Any oiltransmitted must pass fromLtoR.Therefore ,noow canpossibly exceed thetotal capacity oftheedges fromLtoR,whic his7.Butthis means that theow wefound earlier , ofsize7,must beoptimal!
7âŒ˜14âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 215 More generally ,an(s;t)-cutpartitions thevertices into twodisjoint groupsLandRsuch thatsisinLandtisinR.Itscapacity isthetotal capacity oftheedges fromLtoR,andas argued previously ,isanupper bound onanyow: Pickanyowfandany(s;t)-cut(L;R).Then size(f)capacity (L;R). Some cuts arelarge and give loose upper boundsÂ—cut (fs;b;cg;fa;d;e;tg)hasacapacity of 19.Butthere isalso acutofcapacity 7,whic hiseffectively acerticate ofoptimality ofthe maximum ow.This isn't justaluckyproperty ofouroilnetwork; suchacutalways exists . Max-ow min-cut theorem Thesizeofthemaximum ow inanetwork equals thecapacity ofthesmallest (s;t)-cut. Moreover ,ouralgorithm automatically nds thiscutasaby-product! Let'sseewhy thisistrue.Supposefisthenal ow when thealgorithm terminates .We know that nodetisnolonger reachable fromsintheresidual networkGf.LetLbethenodes that arereachable fromsinGf,andletR=VLbetherest ofthenodes .Then (L;R)isa cutinthegraphG: L R ts e0e Weclaim that size(f)=capacity (L;R): Toseethis,observe that bythewayLisdened, anyedge going fromLtoRmust beatfull capacity (inthecurrent owf),and anyedge fromRtoLmust havezero ow.(So,inthe gure ,fe=ceandfe0=0.)Therefore thenetow across (L;R)isexactly thecapacity ofthe cut. 7.2.5 Efciency Eachiteration ofourmaximum-ow algorithm isefcient, requiringO(jEj)time ifadepth- rst orbreadth-rst searc hisused tondanstpath. Buthow many iterations arethere? Suppose alledges intheoriginal network haveinteger capacitiesC.Then aninductive argument shows that oneachiteration ofthealgorithm, theow isalwaysaninteger and increases byaninteger amount. Therefore ,since themaximum ow isatmostCjEj(why?), itfollows that thenumber ofiterations isatmost thismuch.Butthisishardly areassuring bound: what ifCisinthemillions? Weexamine this issue further inExercise 7.31. Itturns outthat itisindeed possible to construct badexamples inwhic hthenumber ofiterations isproportional toC,ifstpaths arenotcarefully chosen. However ,ifpaths arechosen inasensible manner Â—in particular ,by
7âŒ˜15âŒ˜216 Algorithms using abreadth-rst searc h,whic hnds thepath with thefewest edgesÂ—then thenumber of iterations isatmostO(jVjjEj),nomatter what thecapacities are.This latter bound gives anoverall running time ofO(jVjjEj2)formaximum ow.
7âŒ˜16âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 217 Figure 7.6The max-ow algorithm applied tothenetwork ofFigure 7.4. Ateachiteration, thecurrent ow isshown ontheleftandtheresidual network ontheright. Thepaths chosen areshown inbold. Current ow Residual graph (a) sa b cd et sa b cd et33 410 12 1 512 5 (b) sa b cd et 1 111 1 sa b cd et3 410 1 112 1 21 1 1 41 4 (c) sa b cd et 11122 2sa b cd et3 410 1 112 1 42 2 1 32 (d) sa b cd et1122 5 43sa b cd et310 1 1122 2 1 31 145
7âŒ˜17âŒ˜218 Algorithms Figure 7.6Continued Current Flow Residual Graph (e) sa b cd et122 54 51 sa b cd et310 1 112 2 1 54 511 (f) sa b cd et122 54 521 1sa b cd et10 1 112 2 54 52 211
7âŒ˜18âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 219 Figure 7.7Anedge between twopeople means they like eachother .Isitpossible topair everyone uphappily? Alice Beatrice Carol DanielleGIRLS Chet DanBobAlBOYS 7.3 Bipartite matching Figure 7.7shows agraph with four nodes ontheleftrepresenting boys andfour nodes onthe right representing girls.1There isanedge between aboyandgirlifthey likeeachother (for instance ,Allikes allthegirls). Isitpossible tochoose couples sothat everyone hasexactly one partner ,anditissomeone they like? Ingraph-theoretic jargon, isthere aperfect matc hing ? This matc hmaking game canbereduced tothemaximum-ow problem, and thereby to linear programming! Create anew source node ,s,with outgoing edges toalltheboys; anew sink node ,t,with incoming edges from allthegirls; and direct alltheedges intheoriginal bipartite graph from boytogirl(Figure 7.8). Finally ,give every edge acapacity of1.Then there isaperfect matc hing ifandonly ifthisnetwork hasaow whose sizeequals thenumber ofcouples .Can youndsuchaow intheexample? Actually ,thesituation isslightly more complicated than juststated: what iseasy toseeis that theoptimum integer -valued ow corresponds totheoptimum matc hing.Wewould beat abitofalossinterpreting aow that ships 0:7units along theedge AlÂ–Carol, forinstance! 1This kind ofgraph, inwhic hthenodes canbepartitioned into twogroups suchthat alledges arebetween the groups ,iscalled bipartite . Figure 7.8Amatc hmaking network. Eachedge hasacapacity ofone. s t DanBob Chet DanielleBeatriceAlice CarolAl
7âŒ˜19âŒ˜220 Algorithms Fortunately ,themaximum-ow problem hasthefollowing property: ifalledge capacities are integer s,then theoptimal ow found byouralgorithm isintegral .Wecanseethis directly from thealgorithm, whic hinsuchcases would increment theow byaninteger amount on eachiteration. Hence integrality comes forfreeinthemaximum-ow problem. Unfortunately ,thisisthe exception rather than therule: aswewillseeinChapter 8,itisavery difcult problem to ndtheoptimum solution (orforthat matter ,anysolution) ofageneral linear program, ifwe also demand that thevariables beintegers . 7.4 Duality Wehaveseen that innetworks ,ows aresmaller than cuts,butthemaximum ow andmini- mum cutexactly coincide andeachistherefore acerticate oftheother' soptimality .Remark- able asthisphenomenon is,wenow generalize itfrom maximum ow toanyproblem that can besolved bylinear programming! Itturns outthat every linear maximization problem hasa dual minimization problem, andthey relate toeachother inmuchthesame wayasows and cuts. Tounderstand what duality isabout, recall ourintroductory LPwith thetwotypes of chocolate: maxx1+6x2 x1200 x2300 x1+x2400 x1;x20 Simplex declares theoptimum solution tobe(x1;x2)=(100;300),with objective value 1900. Can thisanswer becheckedsomehow? Let'ssee:suppose wetake therst inequality andadd ittosixtimes thesecond inequality .Weget x1+6x22000: This isinteresting ,because ittells usthat itisimpossible toachieve aprot ofmore than 2000.Can weaddtogether some other combination oftheLPconstraints andbring thisupper bound even closer to1900?After alittle experimentation, wend that multiplying thethree inequalities by0,5,and1,respectively ,andadding them upyields x1+6x21900: So1900 must indeed bethebest possible value! Themultipliers (0;5;1)magically constitute a certicate ofoptimality !Itisremarkable that suchacerticate exists forthis LPÂ—and even ifweknew there were one,how would wesystematically goabout nding it?
7âŒ˜20âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 221 Let'sinvestigate theissue bydescribing what weexpect ofthese three multipliers ,call themy1;y2;y3. Multiplier Inequality y1x1200 y2 x2300 y3x1+x2400 Tostart with, theseyi'smust benonnegative ,forotherwise they areunqualied tomultiply inequalities (multiplying aninequality byanegative number would iptheto).After the multiplication andaddition steps ,wegetthebound: (y1+y3)x1+(y2+y3)x2200y1+300y2+400y3: Wewanttheleft-hand side tolook likeourobjective functionx1+6x2sothat theright-hand side isanupper bound ontheoptimum solution. Forthisweneedy1+y3tobe1andy2+y3to be6.Come tothink ofit,itwould beneify1+y3were larger than1Â—the resulting certicate would beallthemore convincing .Thus ,wegetanupper bound x1+6x2200y1+300y2+400y3if8 < :y1;y2;y30 y1+y31 y2+y369 = ;: Wecaneasily ndy'sthat satisfy theinequalities ontheright bysimply making them large enough, forexample (y1;y2;y3)=(5;3;6).Butthese particular multipliers would tellusthat theoptimum solution oftheLPisatmost 2005+3003+4006=4300,abound that isfar tooloose tobeofinterest. What wewantisabound that isastight aspossible ,soweshould minimize 200y1+300y2+400y3subject tothepreceding inequalities .And thisisanew linear program ! Therefore ,nding thesetofmultipliers that gives thebest upper bound onouroriginal LPistantamount tosolving anew LP: min200y1+300y2+400y3 y1+y31 y2+y36 y1;y2;y30 Bydesign, anyfeasible value ofthisdual LPisanupper bound ontheoriginal primal LP.So ifwesomehow nd apair ofprimal anddual feasible values that areequal, then they must both beoptimal. Here isjustsuchapair: Primal :(x1;x2)=(100;300); Dual :(y1;y2;y3)=(0;5;1): They both havevalue 1900,andtherefore they certify eachother' soptimality (Figure 7.9). Amazingly ,thisisnotjustaluckyexample ,butageneral phenomenon. Tostart with, the preceding constructionÂ—creating amultiplier foreachprimal constraint; writing aconstraint
7âŒ˜21âŒ˜222 Algorithms Figure 7.9Bydesign, dual feasible valuesprimal feasible values .The duality theorem tells usthat moreover their optima coincide . Primal Primal feasible This duality gap is zeroopt Dual feasibleObjective valueoptDual Figure 7.10 Ageneric primal LPinmatrix-vector form, anditsdual. Primal LP: maxcTx Axb x0Dual LP: minyTb yTAcT y0 inthedual forevery variable oftheprimal, inwhic hthesum isrequired tobeabove the objective coefcient ofthecorresponding primal variable; andoptimizing thesum ofthemul- tipliers weighted bytheprimal right-hand sidesÂ—can becarried outforanyLP,asshown in Figure 7.10, andineven greater generality inFigure 7.11. Thesecond gure hasonenotewor - thyaddition: iftheprimal hasanequality constraint, then thecorresponding multiplier (or dual variable )need notbenonnegative ,because thevalidity ofequations ispreserved when multiplied bynegative numbers .So,themultipliers ofequations areunrestricted variables . Notice also thesimple symmetry between thetwoLPs,inthat thematrixA=(aij)denes oneprimal constraint with eachofitsrows ,andonedual constraint with eachofitscolumns . Byconstruction, anyfeasible solution ofthedual isanupper bound onanyfeasible solution oftheprimal. Butmoreover ,their optima coincide! Duality theorem Ifalinear program hasabounded optimum, then sodoes itsdual, andthe twooptimum values coincide . When theprimal istheLPthat expresses themax-ow problem, itispossible toassign interpretations tothedual variables that show thedual tobenone other than theminimum- cutproblem (Exercise 7.25). The relation between ows andcuts istherefore just aspecic instance oftheduality theorem. And infact, theproof ofthistheorem falls outofthesimplex algorithm, inmuchthesame wayasthemax-ow min-cut theorem felloutoftheanalysis of themax-ow algorithm.
7âŒ˜22âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 223 Figure 7.11 Inthemost general case oflinear programming ,wehaveasetIofinequalities and asetEofequalities (atotal ofm=jIj+jEjconstraints) overnvariables ,ofwhic ha subsetNareconstrained tobenonnegative .The dual hasm=jIj+jEjvariables ,ofwhic h only those corresponding toIhavenonnegativity constraints . Primal LP: maxc1x1++cnxn ai1x1++ainxnbifori2I ai1x1++ainxn=bifori2E xj0forj2NDual LP: minb1y1++bmym a1jy1++amjymcjforj2N a1jy1++amjym=cjforj62N yi0fori2I Visualizing duality One cansolve theshortest-path problem bythefollowing Â“analogÂ” device: Given aweighted undirected graph, build aphysical model ofitinwhic heachedge isastring oflength equal totheedge' sweight, andeachnode isaknot atwhic htheappropriate endpoints ofstrings aretiedtogether .Then tondtheshortest path fromstot,justpullsawayfromtuntil the gadget istaut. Itisintuitively clear that thisnds theshortest path fromstot. S D CA B T There isnothing remarkable orsurprising about allthis until wenotice thefollowing: theshortest-path problem isaminimization problem, right? Then why arewepullings awayfromt,anactwhose purpose is,obviously ,maximization? Answer: Bypullingsaway fromtwesolve thedual oftheshortest-path problem! This dual hasavery simple form (Exercise 7.28), with onevariablexuforeachnodeu: maxxSxT jxuxvjwuvforalledgesfu;vg Inwords ,thedual problem istostretc hsandtasfarapart aspossible ,subject tothe constraint that theendpoints ofanyedgefu;vgareseparated byadistance ofatmostwuv.
7âŒ˜23âŒ˜224 Algorithms 7.5 Zero-sum games Wecanrepresent various conict situations inlifebymatrix games .Forexample ,theschool- yard rock-paper -scissor sgame isspecied bythepayoff matrix illustrated here.There aretwo players,called Row andColumn, andthey eachpickamove fromfr;p;sg.They then look up thematrix entry corresponding totheir moves ,andColumn paysRow thisamount. ItisRow' s gain andColumn' sloss. G=Column rps r011 p101Rows110 Now suppose thetwoofthem playthis game repeatedly .IfRow alwaysmakes thesame move ,Column will quicklycatchonand will alwaysplaythecountermove ,winning every time.Therefore Row should mix things up:wecanmodel this byallowing Row tohavea mixed strategy ,inwhic honeachturn sheplaysrwith probability x1,pwith probability x2, andswith probability x3.This strategy isspecied bythevector x=(x1;x2;x3),positive numbers that addupto1.Similarly ,Column' smixed strategy issomey=(y1;y2;y3).2 Onanygiven round ofthegame ,there isanxiyjchance that Row andColumn willplay theithandjthmoves ,respectively .Therefore theexpected (average) payoffis X i;jGijProb[Row playsi,Column playsj]=X i;jGijxiyj: Row wants tomaximize this,while Column wants tominimize it.What payoffs canthey hope toachieve inrock-paper -scissors? Well,suppose forinstance that Row playstheÂ“completely randomÂ” strategy x=(1=3;1=3;1=3).IfColumn playsr,then theaverage payoff(reading the rst column ofthegame matrix) willbe 1 30+1 31+1 31=0: This isalso true ifColumn playsp,ors.And since thepayoffofanymixed strategy (y1;y2;y3) isjustaweighted average oftheindividual payoffs forplayingr,p,ands,itmust also bezero. This canbeseen directly from thepreceding formula, X i;jGijxiyj=X i;jGij1 3yj=X jyj X i1 3Gij! =X jyj0=0; where thesecond-to-last equality istheobservation that every column ofGadds uptozero. Thus byplaying theÂ“completely randomÂ” strategy ,Row forces anexpected payoffofzero,no matter what Column does.This means that Column cannot hope foranegative (expected) 2Also ofinterest arescenarios inwhic hplayers alter their strategies from round toround, butthese canget very complicated andareavast subject unto themselves .
7âŒ˜24âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 225 payoff(remember that hewants thepayofftobeassmall aspossible). But symmetrically , ifColumn playsthecompletely random strategy ,healso forces anexpected payoff ofzero, andthus Row cannot hope forapositive (expected) payoff.Inshort, thebest eachplayercan doistoplaycompletely randomly ,with anexpected payoffofzero.Wehavemathematically conrmed what youknew allalong about rock-paper -scissors! Let'sthink about thisinaslightly different way,byconsidering twoscenarios: 1.FirstRow announces herstrategy ,andthen Column pickshis. 2.FirstColumn announces hisstrategy ,andthen Row chooses hers. We've seen that theaverage payoffisthesame (zero) ineither case ifboth parties playop- timally .Butthis might well beduetothehigh level ofsymmetry inrock-paper -scissors .In general games ,we'dexpect therst option tofavorColumn, since heknows Row' sstrategy and canfully exploit itwhile choosing hisown. Likewise ,we'dexpect thesecond option to favorRow.Amazingly ,thisisnotthecase: ifboth playoptimally ,then itdoesn't hurt aplayer toannounce hisorherstrategy inadvance! What' smore ,this remarkable property isacon- sequence ofÂ—and infactequivalent toÂ—linear programming duality . Let'sinvestigate thiswith anonsymmetric game .Imagine apresidential election scenario inwhic hthere aretwocandidates forofce ,andthemoves they make correspond tocampaign issues onwhic hthey canfocus (the initials stand foreconomy ,society ,morality ,andtaxcut). Thepayoffentries aremillions ofvotes lostbyColumn. G=mt e31 s21 Suppose Row announces that shewillplaythemixed strategy x=(1=2;1=2).What should Column do?Movemwillincur anexpected lossof1=2,whiletwillincur anexpected lossof0. Thebest response ofColumn istherefore thepure strategy y=(0;1). More generally ,once Row' sstrategy x=(x1;x2)isxed, there isalwaysapure strategy that isoptimal forColumn: either movem,with payoff3x12x2,ort,with payoffx1+x2, whic hever issmaller .After all,anymixed strategy yisaweighted average ofthese twopure strategies andthus cannot beat thebetter ofthetwo. Therefore ,ifRow isforced toannounce xbefore Column plays,sheknows that hisbest response will achieve anexpected payoffofminf3x12x2;x1+x2g.She should choose x defensivel ytomaximize herpayoffagainst thisbest response: Pick(x1;x2)that maximizes minf3x12x2;x1+x2g|{z} payofffrom Column' sbest response tox This choice ofxi'sgives Row thebest possible guarantee about herexpected payoff.And we willnow seethat itcanbefound byanLP!Themain trickistonotice that forxedx1andx2 thefollowing areequivalent:
7âŒ˜25âŒ˜226 Algorithms z=minf3x12x2;x1+x2gmaxz z3x12x2 zx1+x2 And Row needs tochoosex1andx2tomaximize thisz. maxz 3x1+2x2+z0 x1x2+z0 x1+x2 =1 x1;x20 Symmetrically ,ifColumn hastoannounce hisstrategy rst, hisbest betistochoose the mixed strategy ythat minimizes hislossunder Row' sbest response ,inother words , Pick(y1;y2)that minimizes maxf3y1y2;2y1+y2g|{z} outcome ofRow' sbest response toy InLPform, thisis minw 3y1+y2+w0 2y1y2+w0 y1+y2 =1 y1;y20 The crucial observation now isthat these twoLPs aredual toeachother (see Figure 7.11)! Hence ,they havethesame optimum, callitV. Letussummarize .Bysolving anLP,Row (the maximizer) candetermine astrategy for herself that guarantees anexpected outcome ofatleastVnomatter what Column does.And bysolving thedual LP,Column (theminimizer) canguarantee anexpected outcome ofatmost V,nomatter what Row does.Itfollows that thisistheuniquely dened optimal play:apriori itwasn't even certain that suchaplayexisted.Visknown asthevalue ofthegame .Inour example ,itis1=7andisrealized when Row playsheroptimum mixed strategy (3=7;4=7)and Column playshisoptimum mixed strategy (2=7;5=7). This example iseasily generalized toarbitrary games and shows theexistence ofmixed strategies that areoptimal forboth players andachieve thesame valueÂ—a fundamental result ofgame theory called themin-max theorem .Itcanbewritten inequation form asfollows: max xmin yX i;jGijxiyj=min ymax xX i;jGijxiyj: This issurprising ,because theleft-hand side,inwhic hRow hastoannounce herstrategy rst, should presumably bebetter forColumn than theright-hand side,inwhic hhehastogo rst. Duality equalizes thetwo,asitdidwith maximum ows andminimum cuts.
7âŒ˜26âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 227 Figure 7.12 Apolyhedron dened byseven inequalities . x1 x3x2 1 4 2 3 5 6 7 A B Cmaxx1+6x2+13x3 x1200 1 x2300 2 x1+x2+x3400 3 x2+3x3600 4 x10 5 x20 6 x30 7 7.6 The simplex algorithm Theextraordinary power andexpressiveness oflinear programs would belittle consolation if wedidnothaveawaytosolve them efciently .This istheroleofthesimplex algorithm. Atahigh level, thesimplex algorithm takes asetoflinear inequalities andalinear objec- tivefunction andnds theoptimal feasible point bythefollowing strategy: letvbeanyvertexofthefeasible region whilethereisaneighbor v0ofvwithbetterobjective value: setv=v0 Inour2Dand3Dexamples (Figure 7.1andFigure 7.2), thiswassimple tovisualize andmade intuitive sense .Butwhat ifthere arenvariables ,x1;:::;xn? Any setting ofthexi'scanberepresented byann-tuple ofreal numbers and plotted in n-dimensional space .Alinear equation involving thexi'sdenes ahyperplane inthis same space Rn,and thecorresponding linear inequality denes ahalf-space ,allpoints that are either precisely onthehyperplane orlieononeparticular sideofit.Finally ,thefeasible region ofthelinear program isspecied byasetofinequalities andistherefore theintersection of thecorresponding half-spaces ,aconvex polyhedron. Butwhat dotheconcepts ofvertex andneighbor mean inthisgeneral context? 7.6.1 Vertices and neighbors inn-dimensional space Figure 7.12 recalls anearlier example .Looking atitclosely ,weseethat eachvertex isthe unique point atwhic hsome subset ofhyperplanes meet .VertexA,forinstance ,isthesole point atwhic hconstraints 2 ,3 ,and 7 aresatised with equality .Ontheother hand, the
7âŒ˜27âŒ˜228 Algorithms hyperplanes corresponding toinequalities 4 and 6 donotdene avertex, because their intersection isnotjustasingle point butanentire line. Let'smake thisdenition precise . Pickasubset oftheinequalities .Ifthere isaunique point that satises them with equality ,andthispoint happens tobefeasible ,then itisavertex . How many equations areneeded touniquely identify apoint? When there arenvariables ,we need atleastnlinear equations ifwewantaunique solution. Ontheother hand, having more thannequations isredundant: atleast oneofthem canberewritten asalinear combination oftheothers andcantherefore bedisregarded. Inshort, Eachvertex isspecied byasetofninequalities .3 Anotion ofneighbor now follows naturally . Two vertices areneighbor sifthey haven1dening inequalities incommon. InFigure 7.12, forinstance ,verticesAandCshare thetwodening inequalitiesf3 ;7 gand arethus neighbors . 7.6.2 The algorithm Oneachiteration, simplex hastwotasks: 1.Chec kwhether thecurrent vertex isoptimal (and ifso,halt). 2.Determine where tomove next. Aswewillsee,both tasks areeasy ifthevertex happens tobeattheorigin. And ifthevertex iselsewhere ,wewilltransform thecoordinate system tomove ittotheorigin! Firstlet'sseewhy theorigin issoconvenient. Suppose wehavesome generic LP maxcTx Axb x0 where xisthevector ofvariables ,x=(x1;:::;xn).Suppose theorigin isfeasible .Then itis certainly avertex, since itistheunique point atwhic htheninequalitiesfx10;:::;xn0g aretight .Now let'ssolve ourtwotasks .Task1: Theorigin isoptimal ifandonly ifallci0. 3There isonetrickyissue here.Itispossible that thesame vertex might begenerated bydifferent subsets ofinequalities .InFigure 7.12, vertex Bisgenerated byf2 ;3 ;4 g,butalso byf2 ;4 ;5 g.Suchvertices are called degenerate and require special consideration. Let'sassume forthetime being that they don't exist, and we'll return tothem later .
7âŒ˜28âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 229 Ifallci0,then considering theconstraints x0,wecan't hope forabetter objective value . Conversely ,ifsomeci>0,then theorigin isnotoptimal, since wecanincrease theobjective function byraisingxi. Thus ,fortask 2,wecanmove byincreasing somexiforwhic hci>0.How muchcan weincrease it?Until wehitsome other constraint .That is,werelease thetight constraint xi0and increasexiuntil some other inequality ,previously loose ,now becomes tight. At that point, weagain haveexactlyntight inequalities ,soweareatanew vertex. Forinstance ,suppose we're dealing with thefollowing linear program. max2x1+5x2 2x1x24 1 x1+2x29 2 x1+x23 3 x10 4 x20 5 Simplex canbestarted attheorigin, whic hisspecied byconstraints 4 and 5 .Tomove ,we release thetight constraint x20.Asx2isgradually increased, therst constraint itruns into isx1+x23,andthus ithastostop atx2=3,atwhic hpoint this new inequality is tight. Thenew vertex isthus given by 3 and 4 . Soweknow what todoifweareattheorigin. Butwhat ifourcurrent vertex uiselse- where? Thetrickistotransform uinto theorigin, byshifting thecoordinate system from the usual (x1;:::;xn)totheÂ“local viewÂ” fromu.These local coordinates consist of(appropriately scaled) distancesy1;:::;yntothenhyperplanes (inequalities) that dene andencloseu: y2y1 xu Specically ,ifoneofthese enclosing inequalities isaixbi,then thedistance from apoint xtothat particular Â“wallÂ”is yi=biaix: Thenequations ofthis type,oneperwall,dene theyi'saslinear functions ofthexi's,and this relationship canbeinverted toexpress thexi'sasalinear function oftheyi's.Thus wecanrewrite theentire LPinterms ofthey's.This doesn't fundamentally change it(for instance ,theoptimal value staysthesame), butexpresses itinadifferent coordinate frame . Therevised Â“localÂ” LPhasthefollowing three properties:
7âŒ˜29âŒ˜230 Algorithms 1.Itincludes theinequalities y0,whic haresimply thetransformed versions ofthe inequalities dening u. 2.uitself istheorigin iny-space . 3.The cost function becomes maxcu+~cTy,wherecuisthevalue oftheobjective function atuand~cisatransformed costvector . Inshort, wearebacktothesituation weknow how tohandle! Figure 7.13 shows this algo- rithm inaction, continuing with ourearlier example . The simplex algorithm isnow fully dened. Itmoves from vertex toneighboring vertex, stopping when theobjective function islocally optimal, that is,when thecoordinates ofthe local costvector areallzero ornegative .Aswe've justseen, avertex with thisproperty must also beglobally optimal. Ontheother hand, ifthecurrent vertex isnotlocally optimal, then itslocal coordinate system includes some dimension along whic htheobjective function canbe improved, sowemove along thisdirectionÂ—along thisedge ofthepolyhedronÂ—until wereach aneighboring vertex. Bythenondegeneracy assumption (seefootnote 3inSection 7.6.1), this edge hasnonzero length, and sowestrictly improve theobjective value .Thus theprocess must eventually halt.
7âŒ˜30âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 231 Figure 7.13 Simplex inaction. Initial LP: max2x1+5x2 2x1x24 1 x1+2x29 2 x1+x23 3 x10 4 x20 5 Current vertex:f4 ;5 g(origin). Objective value: 0. Move: increasex2. 5 isreleased, 3 becomes tight. Stop atx2=3. New vertexf4 ;3 ghaslocal coordinates (y1;y2): y1=x1;y2=3+x1x2 Rewritten LP: max15+7y15y2 y1+y27 1 3y12y23 2 y20 3 y10 4 y1+y23 5 Current vertex:f4 ;3 g. Objective value: 15. Move: increasey1. 4 isreleased, 2 becomes tight. Stop aty1=1. New vertexf2 ;3 ghaslocal coordinates (z1;z2): z1=33y1+2y2;z2=y2 Rewritten LP: max227 3z11 3z2 1 3z1+5 3z26 1 z10 2 z20 3 1 3z12 3z21 4 1 3z1+1 3z24 5 Current vertex:f2 ;3 g. Objective value: 22. Optimal: allci<0. Solve 2 ;3 (inoriginal LP) togetoptimal solution (x1;x2)=(1;4). f1 ;2 gf3 ;4 gf2 ;3 g y1 x2Increase Increase f1 ;5 g f4 ;5 g
7âŒ˜31âŒ˜232 Algorithms 7.6.3 Loose ends There areseveral important issues inthesimplex algorithm that wehaven't yetmentioned. The starting vertex. How dowend avertex atwhic htostart simplex? Inour2Dand 3Dexamples wealwaysstarted attheorigin, whic hworked because thelinear programs happened tohaveinequalities with positive right-hand sides .Inageneral LPwewon't always besofortunate .However ,itturns outthat nding astarting vertex canbereduced toanLP andsolved bysimplex! Toseehow this isdone ,start with any linear program instandard form (recall Sec- tion 7.1.4), since weknow LPscanalwaysberewritten thisway. mincTxsuchthatAx=bandx0: Werst make sure that theright-hand sides oftheequations areallnonnegative: ifbi<0, justmultiply both sides oftheithequation by1. Then wecreate anew LPasfollows: Createmnew articial variablesz1;:::;zm0,wheremisthenumber ofequations . Addzitotheleft-hand side oftheithequation. Lettheobjective ,tobeminimized ,bez1+z2++zm. Forthis new LP,it'seasy tocome upwith astarting vertex, namely ,theonewithzi=bifor alliandallother variables zero.Therefore wecansolve itbysimplex, toobtain theoptimum solution. There aretwocases .Iftheoptimum value ofz1++zmiszero,then allzi'sobtained by simplex arezero,andhence from theoptimum vertex ofthenew LPwegetastarting feasible vertex oftheoriginal LP,justbyignoring thezi's.Wecanatlaststart simplex! But what iftheoptimum objective turns outtobepositive? Letusthink. Wetried to minimize thesum ofthezi's,butsimplex decided that itcannot bezero.Butthismeans that theoriginal linear program isinfeasible: itneeds some nonzerozi'stobecome feasible .This ishow simplex discovers andreports that anLPisinfeasible . Degeneracy .Inthepolyhedron ofFigure 7.12 vertexBisdegenerate .Geometrically ,this means that itistheintersection ofmore thann=3faces ofthepolyhedron (inthis case, 2 ;3 ;4 ;5 ).Algebraically ,itmeans that ifwechoose anyoneoffour sets ofthree inequal- ities (f2 ;3 ;4 g;f2 ;3 ;5 g;f2 ;4 ;5 g,andf3 ;4 ;5 g)andsolve thecorresponding system ofthree linear equations inthree unknowns ,we'll getthesame solution inallfour cases: (0;300;100).This isaserious problem: simplex mayreturn asuboptimal degenerate vertex simply because allitsneighbors areidentical toitandthus havenobetter objective .And if wemodify simplex sothat itdetects degeneracy andcontinues tohopfrom vertex tovertex despite lackofanyimprovement inthecost, itmayenduplooping forever . One waytoxthisisbyaperturbation :change eachbibyatiny random amount tobii. This doesn't change theessence oftheLPsince thei'saretiny,butithastheeffect ofdiffer - entiating between thesolutions ofthelinear systems .Toseewhy geometrically ,imagine that
7âŒ˜32âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 233 thefour planes 2 ;3 ;4 ;5 were jolted alittle .Wouldn't vertexBsplit into twovertices ,very closetooneanother? Unboundedness. Insome cases anLPisunbounded, inthat itsobjective function canbe made arbitrarily large (orsmall, ifit'saminimization problem). Ifthis isthecase,simplex will discover it:inexploring theneighborhood ofavertex, itwill notice that taking outan inequality andadding another leads toanunderdetermined system ofequations that hasan innity ofsolutions .And infact(this isaneasy test) thespace ofsolutions contains awhole lineacross whic htheobjective canbecome larger andlarger ,allthewayto1.Inthis case simplex halts andcomplains . 7.6.4 The running time ofsimplex What istherunning time ofsimplex, forageneric linear program maxcTxsuchthatAx0andx0; where there arenvariables andAcontainsminequality constraints? Since itisaniterative algorithm that proceeds from vertex tovertex, let'sstart bycomputing thetime taken fora single iteration. Suppose thecurrent vertex isu.Bydenition, itistheunique point atwhic h ninequality constraints aresatised with equality .Eachofitsneighbors sharesn1ofthese inequalities ,soucanhaveatmostnmneighbors: choose whic hinequality todrop andwhic h new onetoadd. Anaive waytoperform aniteration would betocheckeachpotential neighbor tosee whether itreally isavertex ofthepolyhedron andtodetermine itscost. Finding thecost is quick,justadotproduct, butchecking whether itisatrue vertex involves solving asystem of nequations innunknowns (that is,satisfying thenchosen inequalities exactly) andchecking whether theresult isfeasible .ByGaussian elimination (see thefollowing box) this takes O(n3)time,giving anunappetizing running time ofO(mn4)periteration. Fortunately ,there isamuchbetter way,andthismn4factor canbeimproved tomn,mak- ingsimplex apractical algorithm. Recall ourearlier discussion (Section 7.6.2) about thelocal view from vertex u.Itturns outthat theper-iteration overhead ofrewriting theLPinterms ofthecurrent local coordinates isjustO((m+n)n);this exploits thefactthat thelocal view changes only slightly between iterations ,injustoneofitsdening inequalities . Next, toselect thebest neighbor ,werecall that the(local view of)theobjective function is oftheform Â“maxcu+~cyÂ”wherecuisthevalue oftheobjective function atu.This immediately identies apromising direction tomove: wepickany~ci>0(ifthere isnone ,then thecurrent vertex isoptimal andsimplex halts). Since therestoftheLPhasnow been rewritten interms ofthey-coordinates ,itiseasy todetermine how muchyicanbeincreased before some other inequality isviolated. (And ifwecanincreaseyiindenitely ,weknow theLPisunbounded.) Itfollows that therunning time periteration ofsimplex isjustO(mn).But how many iterations could there be?Naturally ,there can't bemore thanm+n n ,whic hisanupper bound onthenumber ofvertices .Butthis upper bound isexponential inn.And infact, there are examples ofLPs forwhic hsimplex does indeed take anexponential number ofiterations .In
7âŒ˜33âŒ˜234 Algorithms other words ,simplex isanexponential-time algorithm. However ,suchexponential examples donotoccur inpractice ,anditisthisfactthat makes simplex sovaluable andsowidely used.
7âŒ˜34âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 235 Gaussian elimination Under ouralgebraic denition, merely writing down thecoordinates ofavertex involves solving asystem oflinear equations .How isthisdone? Wearegiven asystem ofnlinear equations innunknowns ,sayn=4and x12x3 =2 x2+x3 =3 x1+x2x4=4 x2+3x3+x4=5 The high school method forsolving suchsystems istorepeatedly apply thefollowing rule: ifweadd amultiple ofoneequation toanother equation, theoverall system ofequations remains equivalent. Forexample ,adding1times therst equation tothethird one,weget theequivalent system x12x3 =2 x2+x3 =3 x2+2x3x4=2 x2+3x3+x4=5 This transformation isclever inthefollowing sense: iteliminates thevariablex1from the third equation, leaving justoneequation withx1.Inother words ,ignoring therst equation, wehaveasystem ofthree equations inthree unknowns: wedecreasednby1!Wecansolve thissmaller system togetx2;x3;x4,andthen plug these into therst equation togetx1. This suggests analgorithmÂ—once more duetoGauss . procedure gauss(E;X) Input: AsystemE=fe1;:::;engofequations innunknowns X=fx1;:::;xng: e1:a11x1+a12x2++a1nxn=b1;;en:an1x1+an2x2++annxn=bn Output: Asolution ofthesystem, ifoneexists ifallcoefficients ai1arezero: haltwithmessage ``either infeasible ornotlinearly independent'' ifn=1:returnb1=a11 choosethecoefficient ap1oflargest magnitude, andswapequations e1;ep fori=2ton: ei=ei(ai1=a11)e1 (x2;:::;xn)=gauss (Efe1g;Xfx1g) x1=(b1P j>1a1jxj)=a11 return (x1;:::;xn) (When choosing theequation toswapinto rst place ,wepicktheonewith largestjap1jfor reasons ofnumerical accuracy ;after all,wewillbedividing byap1.) Gaussian elimination usesO(n2)arithmetic operations toreduce theproblem size from nton1,andthus usesO(n3)operations overall. Toshow that thisisalso agood estimate ofthetotal running time,weneed toargue that thenumbers involved remain polynomi- ally boundedÂ—for instance ,that thesolution (x1;:::;xn)does notrequire toomuchmore precision towrite down than theoriginal coefcients aijandbi.Doyouseewhy thisistrue?
7âŒ˜35âŒ˜236 Algorithms Linear programming inpolynomial time Simplex isnotapolynomial time algorithm. Certain rare kinds oflinear programs cause ittogofrom onecorner ofthefeasible region toabetter corner and then toastill better one,andsoonforanexponential number ofsteps .Foralong time,linear programming was considered aparadox, aproblem that canbesolved inpractice ,butnotintheory! Then, in1979, ayoung Soviet mathematician called Leonid Khac hiyan came upwith theellipsoid algorithm ,onethat isvery different from simplex, extremely simple inits conception (but sophisticated initsproof) and yetonethat solves any linear program in polynomial time.Instead ofchasing thesolution from onecorner ofthepolyhedron to thenext, Khac hiyan' salgorithm connes ittosmaller andsmaller ellipsoids (skewed high- dimensional balls). When thisalgorithm wasannounced, itbecame akind ofÂ“mathematical Sputnik, Â”asplashy achievement that hadtheU.S.establishment worried, intheheight of theCold War,about thepossible scientic superiority oftheSoviet Union. The ellipsoid algorithm turned outtobeanimportant theoretical advance ,butdidnotcompete well with simplex inpractice .The paradox oflinear programming deepened: Aproblem with two algorithms ,onethat isefcient intheory ,andonethat isefcient inpractice! Afewyears later Narendra Karmarkar ,agraduate student atUCBerkeley ,came up with acompletely different idea, whic hledtoanother provably polynomial algorithm for linear programming .Karmarkar' salgorithm isknown astheinterior point method ,because itdoes just that: itdashes totheoptimum corner notbyhopping from corner tocorner on thesurface ofthepolyhedron likesimplex does,butbycutting aclever path intheinterior ofthepolyhedron. And itdoes perform well inpractice . But perhaps the greatest advance inlinear programming algorithms wasnot Khac hiyan' stheoretical breakthrough orKarmarkar' snovel approac h,butanunexpected consequence ofthelatter: theerce competition between thetwoapproac hes,simplex and interior point, resulted inthedevelopment ofvery fastcode forlinear programming . 7.7 Postscript: circuit evaluation The importance oflinear programming stems from theastounding variety ofproblems that reduce toitandthereby bear witness toitsexpressive power .Inasense ,thisnext oneisthe ultimate application. Wearegiven aBoolean circuit ,that is,adagofgates ofthefollowing types . Input gates haveindegree zero,with valuetrue orfalse . ANDgates and ORgates haveindegree 2. NOTgates haveindegree 1. Inaddition, oneofthegates isdesignated astheoutput .Here' sanexample .
7âŒ˜36âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 237 trueANDNOTAND OR OR NOToutput false true The CIRCUITVALUEproblem isthefollowing: when thelawsofBoolean logic areapplied to thegates intopological order ,does theoutput evaluate totrue ? There isasimple ,automatic wayoftranslating thisproblem intoalinear program. Create avariablexgforeachgateg,with constraints 0xg1.Add additional constraints foreach type ofgate: gategg g xg=1xhAND NOT OR xgxh xgxh0xgxh xgxh0 xgxh+xh0h h h0h0h xgxh+xh01false trueg xg=1xg=0g These constraints force allthegates totake onexactly theright valuesÂ— 0forfalse ,and1 fortrue .Wedon't need tomaximize orminimize anything ,andwecanread theanswer off from thevariablexocorresponding totheoutput gate. This isastraightforw ardreduction tolinear programming ,from aproblem that maynot seem very interesting atrst. However ,the CIRCUITVALUEproblem isinasense themost general problem solvable inpolynomial time! After all,anyalgorithm willeventually runon acomputer ,andthecomputer isultimately aBoolean combinational circuit implemented on achip.Ifthealgorithm runs inpolynomial time,itcanberendered asaBoolean circuit con- sisting ofpolynomially many copies ofthecomputer' scircuit, oneperunit oftime,with the values ofthegates inonelayerused tocompute thevalues forthenext. Hence ,thefactthat CIRCUITVALUEreduces tolinear programming means that allproblems that canbesolved in polynomial time do!
7âŒ˜37âŒ˜238 Algorithms Inournext topic ,NP-completeness ,weshall seethat many hard problems reduce ,much thesame way,tointeger programming ,linear programming' sdifcult twin. Another parting thought: bywhat other means canthecircuit evaluation problem be solved? Let'sthinkÂ—a circuit isadag.And what algorithmic technique ismost appropriate forsolving problems ondags? That' sright: dynamic programming! Together with linear programming ,theworld' stwomost general algorithmic techniques .
7âŒ˜38âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 239 Exercises 7.1. Consider thefollowing linear program. maximize 5x+3y 5x2y0 x+y7 x5 x0 y0 Plot thefeasible region andidentify theoptimal solution. 7.2. Duckwheat isproduced inKansas andMexico andconsumed inNew YorkandCalifornia. Kansas produces 15shnupells ofduckwheat andMexico 8.Meanwhile ,New Yorkconsumes 10shnupells and California 13.The transportation costs pershnupell are$4from Mexico toNew York, $1 from Mexico toCalifornia, $2from Kansas toNew York, and$3andfrom Kansas toCalifornia. Write alinear program that decides theamounts ofduckwheat (inshnupells andfractions ofa shnupell) tobetransported from eachproducer toeachconsumer ,soastominimize theoverall transportation cost. 7.3. Acargo plane cancarry amaximum weight of100tons and amaximum volume of60cubic meters .There arethree materials tobetransported, andthecargo company maychoose tocarry anyamount ofeach,upto themaximum available limits given below . Material 1hasdensity 2tons/cubic meter ,maximum available amount 40cubic meters ,and revenue $1,000 percubic meter . Material 2hasdensity 1ton/cubic meter ,maximum available amount 30cubic meters ,and revenue $1,200 percubic meter . Material 3hasdensity 3tons/cubic meter ,maximum available amount 20cubic meters ,and revenue $12,000 percubic meter . Write alinear program that optimizes revenue within theconstraints . 7.4. Moe isdeciding how muchRegular Duff beer andhow muchDuff Strong beer toorder eachweek. Regular Duff costs Moe$1perpint andhesells itat$2perpint; Duff Strong costs Moe$1:50per pint andhesells itat$3perpint. However ,aspart ofacomplicated marketing scam, theDuff company willonly sellapint ofDuff Strong foreachtwopints ormore ofRegular Duff that Moe buys .Furthermore ,duetopast events that arebetter leftuntold, Duff willnotsellMoe more than3;000pints perweek. Moe knows that hecansellhowever muchbeer hehas.Formulate a linear program fordeciding how muchRegular Duff andhow muchDuff Strong tobuy,soasto maximize Moe' sprot. Solve theprogram geometrically . 7.5. The Canine Products company offers twodogfoods ,Frisky Pup and Husky Hound, that are made from ablend ofcereal andmeat. Apackage ofFrisky Pup requires 1pound ofcereal and 1:5pounds ofmeat, and sells for$7.Apackage ofHusky Hound uses2pounds ofcereal and 1pound ofmeat, and sells for$6.Rawcereal costs $1perpound and rawmeat costs $2per pound. Italso costs $1:40topackage theFrisky Pup and$0:60topackage theHusky Hound. A total of240;000pounds ofcereal and180;000pounds ofmeat areavailable eachmonth. Theonly production bottlenec kisthat thefactory canonly package110;000bags ofFrisky Pup permonth. Needless tosay,management would liketomaximize prot.
7âŒ˜39âŒ˜240 Algorithms (a)Formulate theproblem asalinear program intwovariables . (b)Graph thefeasible region, give thecoordinates ofevery vertex, andcirclethevertex maxi- mizing prot. What isthemaximum prot possible? 7.6. Give anexample ofalinear program intwovariables whose feasible region isinnite ,butsuch that there isanoptimum solution ofbounded cost. 7.7. Findnecessary andsufcient conditions ontherealsaandbunder whic hthelinear program maxx+y ax+by1 x;y0 (a)Isinfeasible . (b)Isunbounded. (c)Has aunique optimal solution. 7.8. Youaregiven thefollowing points intheplane: (1;3);(2;5);(3;7);(5;11);(7;14);(8;15);(10;19): Youwanttond alineax+by=cthat approximately passes through these points (nolineisa perfect t).Write alinear program (you don't need tosolve it)tondthelinethat minimizes the maximum absolute error , max 1i7jaxi+byicj: 7.9. Aquadratic programming problem seeks tomaximize aquadratric objective function (with terms like3x2 1or5x1x2)subject toasetoflinear constraints .Give anexample ofaquadratic program intwovariablesx1;x2suchthat thefeasible region isnonempty andbounded, andyetnone of thevertices ofthisregion optimize the(quadratic) objective . 7.10. Forthefollowing network, with edge capacities asshown, nd themaximum ow fromStoT, along with amatc hing cut. A B CG TD E F4 16 102202 51 105 412 62 S 7.11. Write thedual tothefollowing linear program. maxx+y 2x+y3 x+3y5 x;y0 Findtheoptimal solutions toboth primal anddual LPs.
7âŒ˜40âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 241 7.12. Forthelinear program maxx12x3 x1x21 2x2x31 x1;x2;x30 prove that thesolution (x1;x2;x3)=(3=2;1=2;0)isoptimal. 7.13. Matc hing pennies .Inthissimple two-pla yergame ,theplayers (call themRandC)eachchoose anoutcome ,heads ortails.Ifboth outcomes areequal,Cgives adollar toR;iftheoutcomes are different,Rgives adollar toC. (a)Represent thepayoffs bya22matrix. (b)What isthevalue ofthisgame ,andwhat aretheoptimal strategies forthetwoplayers? 7.14. The pizza business inLittle Town issplit between tworivals ,Tonyand Joey.They areeach investigating strategies tosteal business awayfrom theother .Joeyisconsidering either lowering prices orcutting bigger slices .Tonyislooking intostarting upalineofgourmet pizzas ,oroffering outdoor seating ,orgiving free sodas atlunchtime .The effects ofthese various strategies are summarized inthefollowing payoffmatrix (entries aredozens ofpizzas ,Joey'sgain andTony's loss). TONY Gourmet Seating Freesoda JOEYLower price +2 03 Bigger slices12 +1 Forinstance ,ifJoeyreduces prices andTonygoes with thegourmet option, then Tonywilllose2 dozen pizzas worth ofbusiness toJoey. What isthevalue ofthisgame ,andwhat aretheoptimal strategies forTonyandJoey? 7.15. Findthevalue ofthegame specied bythefollowing payoffmatrix. 0011 0121 1111 1001 1203 1111 0321 0211 (Hint: Consider themixed strategies (1=3;0;0;1=2;1=6;0;0;0)and(2=3;0;0;1=3).) 7.16. Asalad isanycombination ofthefollowing ingredients: (1)tomato ,(2)lettuce ,(3)spinac h,(4) carrot, and (5)oil. Eachsalad must contain: (A)atleast 15grams ofprotein, (B)atleast 2 andatmost 6grams offat,(C)atleast 4grams ofcarbohydrates ,(D)atmost 100milligrams of sodium. Furthermore ,(E)youdonotwantyour salad tobemore than 50% greens bymass .The nutritional contents ofthese ingredients (per 100grams) are
7âŒ˜41âŒ˜242 Algorithms ingredient energy protein fat carbohydrate sodium (kcal) (grams) (grams) (grams) (milligrams) tomato 21 0.85 0.33 4.64 9.00 lettuce 16 1.62 0.20 2.37 8.00 spinac h 371 12.78 1.58 74.69 7.00 carrot 346 8.39 1.39 80.70 508.20 oil 884 0.00 100.00 0.00 0.00 Findalinear programming applet ontheWeband useittomake thesalad with thefewest calories under thenutritional constraints .Describe your linear programming formulation and theoptimal solution (thequantity ofeachingredient andthevalue). Cite theWebresources that youused. 7.17. Consider thefollowing network (the numbers areedge capacities). A BC DT S7 6 34 2 2 59 (a)Findthemaximum owfandaminimum cut. (b)Drawtheresidual graphGf(along with itsedge capacities). Inthisresidual network, mark thevertices reachable fromSandthevertices from whic hTisreachable . (c)Anedge ofanetwork iscalled abottlenec kedge ifincreasing itscapacity results inan increase inthemaximum ow.List allbottlenec kedges intheabove network. (d)Give avery simple example (containing atmost four nodes) ofanetwork whic hhasno bottlenec kedges . (e)Give anefcient algorithm toidentify allbottlenec kedges inanetwork. (Hint: Start by running theusual network ow algorithm, andthen examine theresidual graph.) 7.18. There aremany common variations ofthemaximum ow problem. Here arefour ofthem. (a)There aremany sources andmany sinks ,andwewish tomaximize thetotal ow from all sources toallsinks . (b)Eachvertex also hasacapacity onthemaximum ow that canenter it. (c)Eachedge hasnotonly acapacity ,butalso alower bound ontheow itmust carry . (d)Theoutgoing ow from eachnodeuisnotthesame astheincoming ow,butissmaller by afactor of(1u),whereuisalosscoefcient associated with nodeu. Eachofthese canbesolved efciently .Show thisbyreducing (a)and(b)totheoriginal max-ow problem, andreducing (c)and(d)tolinear programming . 7.19. Suppose someone presents youwith asolution toamax-ow problem onsome network. Give a linear time algorithm todetermine whether thesolution does indeed give amaximum ow.
7âŒ˜42âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 243 7.20. Consider thefollowing generalization ofthemaximum ow problem. Youaregiven adirected networkG=(V;E)with edge capacitiesfceg.Instead ofasingle (s;t) pair,youaregiven multiple pairs (s1;t1);(s2;t2);:::;(sk;tk),where thesiaresources ofGandthe tiaresinks ofG.Youarealso givenkdemandsd1;:::;dk.Thegoal istondkowsf(1);:::;f(k) with thefollowing properties: f(i)isavalid ow fromsitoti. Foreachedgee,thetotal owf(1) e+f(2) e++f(k) edoes notexceed thecapacityce. Thesizeofeachowf(i)isatleast thedemanddi. Thesizeofthetotal ow (the sum oftheows) isaslarge aspossible . How would yousolve thisproblem? 7.21. Anedge ofaow network iscalled critical ifdecreasing thecapacity ofthis edge results ina decrease inthemaximum ow.Give anefcient algorithm that nds acritical edge inanetwork. 7.22. Inaparticular networkG=(V;E)whose edges haveinteger capacitiesce,wehavealready found themaximum owffrom nodestonodet.However ,wenow nd outthat oneofthecapacity values weused waswrong: foredge(u;v)weusedcuvwhereas itshould havebeencuv1.This isunfortunate because theowfuses that particular edge atfullcapacity:fuv=cuv. Wecould redo theow computation from scratc h,butthere' safaster way.Show how anew optimal ow canbecomputed inO(jVj+jEj)time. 7.23. Avertex cover ofanundirected graphG=(V;E)isasubset ofthevertices whic htouchesevery edgeÂ—that is,asubsetSVsuchthat foreachedgefu;vg2E,oneorboth ofu;vareinS. Show that theproblem ofnding theminimum vertex cover inabipartite graph reduces tomax- imum ow.(Hint: Can yourelate thisproblem totheminimum cutinanappropriate network?) 7.24. Direct bipartite matc hing.We'veseen how tondamaximum matc hing inabipartite graph via reduction tothemaximum ow problem. Wenow develop adirect algorithm. LetG=(V1[V2;E)beabipartite graph (soeachedge hasoneendpoint inV1andoneendpoint in V2),andletM2Ebeamatc hing inthegraph (that is,asetofedges that don't touch).Avertex issaid tobecovered byMifitistheendpoint ofoneoftheedges inM.Analternating path is apath ofoddlength that starts andends with anon-covered vertex, andwhose edges alternate betweenMandEM. (a)Inthebipartite graph below ,amatc hingMisshown inbold. Findanalternating path. A B C DE F G H I
7âŒ˜43âŒ˜244 Algorithms (b)Prove that amatc hingMismaximal ifandonly ifthere does notexist analternating path with respect toit. (c)Design analgorithm that nds analternating path inO(jVj+jEj)time using avariant of breadth-rst searc h. (d)Give adirectO(jVjjEj)algorithm fornding amaximal matc hing inabipartite graph. 7.25. Thedual ofmaximum ow.Consider thefollowing network with edge capacities . S BTA 1 32 11 (a)Write theproblem ofnding themaximum ow fromStoTasalinear program. (b)Write down thedual ofthislinear program. There should beadual variable foreachedge ofthenetwork andforeachvertex other thanS;T. Now we'll solve thesame problem infullgenerality .Recall thelinear program forageneral maximum ow problem (Section 7.2). (c)Write down thedual ofthis general ow LP,using avariableyeforeachedge andxufor eachvertexu6=s;t. (d)Show that anysolution tothegeneral dual LPmust satisfy thefollowing property: forany directed path fromstotinthenetwork, thesum oftheyevalues along thepath must beat least 1. (e)What aretheintuitive meanings ofthedual variables? Show that anystcutinthe network canbetranslated intoadual feasible solution whose costisexactly thecapacity of that cut. 7.26. Inasatisable system oflinear inequalities a11x1++a1nxnb1 ... am1x1++amnxnbm wedescribe thejthinequality asforced-equal ifitissatised with equality byevery solution x=(x1;:::;xn)ofthesystem. Equivalently ,P iajixibjisnotforced-equal ifthere exists anx that satises thewhole system andsuchthatP iajixi<bj. Forexample ,in x1+x22 x1x22 x11 x20
7âŒ˜44âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 245 therst twoinequalities areforced-equal, while thethird and fourth arenot. Asolution xto thesystem iscalled characteristic if,forevery inequality Ithat isnotforced-equal, xsatisesI without equality .Intheinstance above ,suchasolution is(x1;x2)=(1;3),forwhic hx1<1and x2<0whilex1+x2=2andx1x2=2. (a)Show that anysatisable system hasacharacteristic solution. (b)Given asatisable system oflinear inequalities ,show how touselinear programming to determine whic hinequalities areforced-equal, andtondacharacteristic solution. 7.27. Show that thechange-making problem (Exercise 6.17) canbeformulated asaninteger linear program. Can wesolve thisprogram asanLP,inthecertainty that thesolution willturn outto beintegral (asinthecase ofbipartite matc hing)? Either prove itorgive acounterexample . 7.28. Alinear program forshortest path. Suppose wewanttocompute theshortest path from nodes tonodetinadirected graph with edge lengthsle>0. (a)Show that this isequivalent tonding anstowfthat minimizesP elefesubject to size(f)=1.There arenocapacity constraints . (b)Write theshortest path problem asalinear program. (c)Show that thedual LPcanbewritten as maxxsxt xuxvluvforall(u;v)2E (d)Aninterpretation forthedual isgiven intheboxonpage 223. Why isn't ourdual LP identical totheoneonthat page? 7.29. Hollywood. Alm producer isseeking actors and investors forhisnew movie .There aren available actors; actorichargessidollars .Forfunding ,there aremavailable investors .Investor jwill providepjdollars ,butonly onthecondition that certain actorsLjf1;2;:::;ngare included inthecast (allofthese actorsLjmust bechosen inorder toreceive funding from investorj). The producer' sprot isthesum ofthepayments from investors minus thepayments toactors . Thegoal istomaximize thisprot. (a)Express this problem asaninteger linear program inwhic hthevariables take onvalues f0;1g. (b)Now relax thistoalinear program, andshow that there must infactbeanintegral optimal solution (asisthecase,forexample ,with maximum ow andbipartite matc hing). 7.30. Hall' stheorem. Returning tothematc hmaking scenario ofSection 7.3,suppose wehaveabipar - titegraph with boys ontheleftandanequal number ofgirls ontheright. Hall' stheorem says that there isaperfect matc hing ifandonly ifthefollowing condition holds: anysubsetSofboys isconnected toatleastjSjgirls. Prove thistheorem. (Hint: Themax-ow min-cut theorem should behelpful.) 7.31. Consider thefollowing simple network with edge capacities asshown.
7âŒ˜45âŒ˜246 Algorithms S BTA 11000 1000 10001000 (a)Show that, iftheFord-Fulkerson algorithm isrunonthisgraph, acareless choice ofupdates might cause ittotake1000 iterations .Imagine ifthecapacities were amillion instead of 1000! Wewillnow nd astrategy forchoosing paths under whic hthealgorithm isguaranteed toter- minate inareasonable number ofiterations . Consider anarbitrary directed network (G=(V;E);s;t;fceg)inwhic hwewanttondthemax- imum ow.Assume forsimplicity that alledge capacities areatleast 1,anddene thecapacity ofanstpath tobethesmallest capacity ofitsconstituent edges .Thefattest path fromstotis thepath with themost capacity . (b)Show that thefatteststpath inagraph canbecomputed byavariant ofDijkstra' s algorithm. (c)Show that themaximum ow inGisthesum ofindividual ows along atmostjEjpaths fromstot. (d)Now show that ifwealwaysincrease ow along thefattest path intheresidual graph, then theFord-Fulkerson algorithm willterminate inatmostO(jEjlogF)iterations ,whereFis thesize ofthemaximum ow.(Hint: Itmight help torecall theproof forthegreedy set cover algorithm inSection 5.4.) Infact, aneven simpler ruleÂ—nding apath intheresidual graph using breadth-rst searc hÂ— guarantees that atmostO(jVjjEj)iterations willbeneeded.
