ChapterâŒ˜PageâŒ˜Text
5âŒ˜0âŒ˜Chapter 5 Greedy algorithms Agame like chess canbewon only bythinking ahead :aplayerwho isfocused entirely on immediate advantage iseasy todefeat. But inmany other games ,suchasScrabble ,itis possible todoquite well bysimply making whic hever move seems best atthemoment andnot worrying toomuchabout future consequences . This sort ofmyopic beha vior iseasy andconvenient, making itanattractive algorithmic strategy .Greedy algorithms build upasolution piece bypiece ,alwayschoosing thenext piece that offers themost obvious andimmediate benet. Although suchanapproac hcanbe disastrous forsome computational tasks ,there aremany forwhic hitisoptimal. Our rst example isthat ofminimum spanning trees . 5.1 Minimum spanning trees Suppose youareasked tonetwork acollection ofcomputers bylinking selected pairs ofthem. This translates into agraph problem inwhic hnodes arecomputers ,undirected edges are potential links ,and thegoal istopickenough ofthese edges that thenodes areconnected. Butthisisnotall;eachlinkalsohasamaintenance cost, reected inthat edge' sweight. What isthecheapest possible network? A BC DE F41 43 42 5 64 One immediate observation isthat theoptimal setofedges cannot contain acycle,because removing anedge from thiscyclewould reduce thecostwithout compromising connectivity: Property 1Removing acycleedge cannot disconnect agraph. Sothesolution must beconnected andacyclic:undirected graphs ofthis kind arecalled trees .The particular tree wewantistheonewith minimum total weight, known asthe minimum spanning tree.Here isitsformal denition. 139
5âŒ˜1âŒ˜140 Algorithms Input: Anundirected graphG=(V;E);edge weightswe. Output: AtreeT=(V;E0),withE0E,that minimizes weight (T)=X e2E0we: Inthepreceding example ,theminimum spanning tree hasacostof16: A BC DE F1 42 54 However ,thisisnottheonly optimal solution. Can youspot another? 5.1.1 Agreedy approach Kruskal' sminimum spanning tree algorithm starts with theempty graph and then selects edges fromEaccording tothefollowing rule. Repeatedly addthenext lightest edge that doesn't produce acycle. Inother words ,itconstructs thetree edge byedge and, apart from taking care toavoid cycles, simply pickswhic hever edge ischeapest atthemoment. This isagreedy algorithm: every decision itmakes istheonewith themost obvious immediate advantage . Figure 5.1shows anexample .Westart with anempty graph and then attempt toadd edges inincreasing order ofweight (ties arebroken arbitrarily): BC;CD;BD;CF;DF;EF;AD;AB;CE;AC: The rst twosucceed, butthethird,BD,would produce acycleifadded. Soweignore it andmove along .Thenal result isatree with cost14,theminimum possible . The correctness ofKruskal' smethod follows from acertain cutproperty ,whic hisgeneral enough toalso justify awhole slew ofother minimum spanning tree algorithms . Figure 5.1Theminimum spanning tree found byKruskal' salgorithm. BA6 5 3 4 2F DC E 5 4124 BA F DC E
5âŒ˜2âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 141 Trees Atreeisanundirected graph that isconnected and acyclic.Muchofwhat makes trees so useful isthesimplicity oftheir structure .Forinstance , Property 2Atree onnnodes hasn1edges . This canbeseen bybuilding thetree oneedge atatime,starting from anempty graph. Initially eachofthennodes isdisconnected from theothers ,inaconnected component by itself .Asedges areadded, these components merge .Since eachedge unites twodifferent components ,exactlyn1edges areadded bythetime thetree isfully formed. Inalittle more detail: When aparticular edgefu;vgcomes up,wecanbesure thatu andvlieinseparate connected components ,forotherwise there would already beapath between them andthis edge would create acycle.Adding theedge then merges these two components ,thereby reducing thetotal number ofconnected components byone.Over the course ofthis incremental process ,thenumber ofcomponents decreases fromntoone, meaning thatn1edges must havebeen added along theway. Theconverse isalso true. Property 3Any connected, undirected graphG=(V;E)withjEj=jVj1isatree. Wejustneed toshow thatGisacyclic.One waytodothisistorunthefollowing iterative procedure onit:while thegraph contains acycle,remove oneedge from this cycle.The process terminates with some graphG0=(V;E0);E0E,whic hisacyclicand, byProperty 1 (from page 139), isalso connected. Therefore G0isatree,whereuponjE0j=jVj1by Property 2.SoE0=E,noedges were removed, andGwasacyclictostart with. Inother words ,wecantellwhether aconnected graph isatree just bycounting how many edges ithas.Here' sanother characterization. Property 4Anundirected graph isatree ifandonly ifthere isaunique path between any pair ofnodes . Inatree,any twonodes canonly haveonepath between them; forifthere were two paths ,theunion ofthese paths would contain acycle. Ontheother hand, ifagraph hasapath between anytwonodes ,then itisconnected. If these paths areunique ,then thegraph isalso acyclic(since acyclehastwopaths between anypair ofnodes).
5âŒ˜3âŒ˜142 Algorithms Figure 5.2T[feg.The addition ofe(dotted) toT(solid lines) produces acycle.This cycle must contain atleast oneother edge,shown here ase0,across thecut(S;VS).          eS VS e0 5.1.2 The cutproperty Saythat intheprocess ofbuilding aminimum spanning tree (MST), wehavealready chosen some edges andaresofarontheright track.Whic hedge should weaddnext? Thefollowing lemma gives usalotofexibility inourchoice . Cutproperty Suppose edgesXarepart ofaminimum spanning treeofG=(V;E).Pickany subset ofnodesSforwhic hXdoes notcross betweenSandVS,andletebethelightest edge across thispartition. ThenX[fegispart ofsome MST . Acutisanypartition ofthevertices intotwogroups ,SandVS.What thisproperty says isthat itisalwayssafe toaddthelightest edge across anycut(that is,between avertex inS andoneinVS),providedXhasnoedges across thecut. Let'sseewhy thisholds .EdgesXarepart ofsome MSTT;ifthenew edgeealso happens tobepart ofT,then there isnothing toprove .SoassumeeisnotinT.Wewillconstruct a different MSTT0containing X[fegbyalteringTslightly ,changing justoneofitsedges . Add edgeetoT.SinceTisconnected, italready hasapath between theendpoints ofe,so addingecreates acycle.This cyclemust also havesome other edgee0across thecut(S;VS) (Figure 8.3). Ifwenow remove this edge,weareleftwithT0=T[fegfe0g,whic hwewill show tobeatree.T0isconnected byProperty 1,sincee0isacycleedge.And ithasthesame number ofedges asT;sobyProperties 2and3,itisalso atree. Moreover ,T0isaminimum spanning tree.Compare itsweight tothat ofT: weight (T0)=weight (T)+w(e)w(e0): Botheande0cross betweenSandVS,andeisspecically thelightest edge ofthis type. Thereforew(e)w(e0),andweight (T0)weight (T).SinceTisanMST ,itmust bethecase that weight (T0)=weight (T)andthatT0isalso anMST . Figure 5.3shows anexample ofthecutproperty .Whic hedge ise0?
5âŒ˜4âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 143 Figure 5.3Thecutproperty atwork. (a)Anundirected graph. (b)SetXhasthree edges ,and ispart oftheMSTTontheright. (c)IfS=fA;B;C;Dg,then oneoftheminimum-weight edges across thecut(S;VS)ise=fD;Eg.X[fegispart ofMSTT0,shown ontheright. (a)A BC E F D22 33 4 11 2 1 (b) EdgesX:A BC E F DMSTT:A BC E F D (c) Thecut:A BC E F De S VSMSTT0:A BC E F D 5.1.3 Kruskal' salgorithm Weareready tojustify Kruskal' salgorithm. Atanygiven moment, theedges ithasalready chosen form apartial solution, acollection ofconnected components eachofwhic hhasatree structure .The next edgeetobeadded connects twoofthese components; callthemT1and T2.Sinceeisthelightest edge that doesn't produce acycle,itiscertain tobethelightest edge betweenT1andVT1andtherefore satises thecutproperty . Now wellinsome implementation details .Ateachstage ,thealgorithm chooses anedge toaddtoitscurrent partial solution. Todoso,itneeds totesteachcandidate edgeuvto seewhether theendpointsuandvlieindifferent components; otherwise theedge produces a cycle.And once anedge ischosen, thecorresponding components need tobemerged. What kind ofdata structure supports suchoperations? Wewillmodel thealgorithm' sstate asacollection ofdisjoint sets,eachofwhic hcontains thenodes ofaparticular component. Initially eachnode isinacomponent byitself: makeset (x):create asingleton setcontaining justx. Werepeatedly testpairs ofnodes toseeifthey belong tothesame set. find (x):towhic hsetdoesxbelong?
5âŒ˜5âŒ˜144 Algorithms Figure 5.4Kruskal' sminimum spanning tree algorithm. procedure kruskal(G;w) Input: Aconnected undirected graphG=(V;E)withedgeweightswe Output: Aminimum spanning treedefined bytheedgesX forallu2V: makeset (u) X=fg SorttheedgesEbyweight foralledgesfu;vg2E,inincreasing orderofweight: iffind(u)6=find(v): addedgefu;vgtoX union (u;v) And whenever weaddanedge,wearemerging twocomponents . union (x;y):merge thesets containing xandy. The nal algorithm isshown inFigure 5.4. ItusesjVjmakeset ,2jEjfind ,andjVj1 union operations . 5.1.4 Adata structure fordisjoint sets Union byrank One waytostore asetisasadirected tree (Figure 5.5). Nodes ofthetree areelements ofthe set,arranged innoparticular order ,andeachhasparent pointers that eventually lead upto theroot ofthetree.This root element isaconvenient representative ,orname ,fortheset.It isdistinguished from theother elements bythefactthat itsparent pointer isaself-loop . Figure 5.5Adirected-tree representation oftwosetsfB;EgandfA;C;D;F;G;Hg. E H B C F AD G
5âŒ˜6âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 145 Inaddition toaparent pointer,eachnode alsohasarank that, forthetime being ,should beinterpreted astheheight ofthesubtree hanging from that node . procedure makeset(x) (x)=x rank(x)=0 function find(x) whilex6=(x):x=(x) returnx Ascanbeexpected, makeset isaconstant-time operation. Ontheother hand,find follows parent pointers totheroot ofthetree andtherefore takes time proportional totheheight of thetree.The tree actually gets built viathethird operation, union ,and sowemust make sure that thisprocedure keeps trees shallow . Merging twosets iseasy: make theroot ofonepoint totheroot oftheother .Butwehave achoice here.Iftherepresentatives (roots) ofthesets arerxandry,dowemakerxpoint toryortheother wayaround? Since tree height isthemain impediment tocomputational efciency ,agood strategy istomake theroot oftheshorter treepoint totheroot ofthetaller tree.This way,theoverall height increases only ifthetwotrees being merged areequally tall. Instead ofexplicitly computing heights oftrees ,wewill usetherank numbers oftheir root nodesÂ—whic hiswhy thisscheme iscalled union byrank . procedure union(x;y) rx=find(x) ry=find(y) ifrx=ry:return ifrank(rx)>rank(ry): (ry)=rx else: (rx)=ry ifrank(rx)=rank(ry):rank(ry)=rank(ry)+1 SeeFigure 5.6foranexample . Bydesign, therank ofanode isexactly theheight ofthesubtree rooted atthat node .This means ,forinstance ,that asyoumove upapath towardarootnode ,therank values along the wayarestrictly increasing . Property 1Foranyx,rank(x)<rank((x)). Aroot node with rankkiscreated bythemerger oftwotrees with roots ofrankk1.It follows byinduction (tryit!)that Property 2Any root node ofrankkhasatleast 2knodes initstree.
5âŒ˜7âŒ˜146 Algorithms This extends tointernal (nonroot) nodes aswell: anode ofrankkhasatleast 2kde- scendants .After all,anyinternal node wasonce aroot, and neither itsrank noritssetof descendants haschanged since then. Moreover ,different rank-knodes cannot havecommon descendants ,since byProperty 1any element hasatmost oneancestor ofrankk.Whic h means Property 3Ifthere arenelements overall, there canbeatmostn=2knodes ofrankk. This lastobservation implies ,crucially ,that themaximum rank islogn.Therefore ,allthe trees haveheightlogn,andthisisanupper bound ontherunning time offind andunion . Figure 5.6Asequence ofdisjoint-set operations .Superscripts denote rank. Aftermakeset (A);makeset (B);:::;makeset (G): A0B0C0D0E0F0 0G Afterunion (A;D);union (B;E);union (C;F): A0B0C0G0F1E1D1 Afterunion (C;G);union (E;A): B1F1 C0G 0ED2 A0 0 Afterunion (B;G): A G0F E1 0 C0D2 B01
5âŒ˜8âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 147 Pathcompression Withthedata structure aspresented sofar,thetotal time forKruskal' salgorithm becomes O(jEjlogjVj)forsorting theedges (remember ,logjEjlogjVj)plus anotherO(jEjlogjVj)for theunion andfind operations that dominate therestofthealgorithm. Sothere seems tobe little incentive tomake ourdata structure anymore efcient. Butwhat iftheedges aregiven toussorted? Oriftheweights aresmall (say,O(jEj))so that sorting canbedone inlinear time? Then thedata structure part becomes thebottlenec k, and itisuseful tothink about improving itsperformance beyond lognperoperation. Asit turns out,theimproved data structure isuseful inmany other applications . Buthow canweperformunion 'sandfind 'sfaster thanlogn?The answer is,bybeing a little more careful tomaintain ourdata structure ingood shape .Asanyhousekeeper knows , alittle extra effort putinto routine maintenance canpayoffhandsomely inthelong run, by forestalling major calamities .Wehaveinmind aparticular maintenance operation forour union-nd data structure ,intended tokeep thetrees shortÂ— during eachfind ,when aseries ofparent pointers isfollowed uptotheroot ofatree,wewill change allthese pointers so that they point directly totheroot (Figure 5.7). This path compression heuristic only slightly increases thetime needed forafind andiseasy tocode. function find(x) ifx6=(x):(x)=find((x)) return(x) The benet ofthis simple alteration islong-term rather than instantaneous andthus neces- sitates aparticular kind ofanalysis: weneed tolook atsequences offind andunion opera- tions ,starting from anempty data structure ,anddetermine theaverage time peroperation. This amortized costturns outtobejustbarely more thanO(1),down from theearlierO(logn). Think ofthedata structure ashaving aÂ“top levelÂ” consisting oftheroot nodes ,andbelow it,theinsides ofthetrees .There isadivision oflabor:find operations (with orwithout path compression) only touchtheinsides oftrees ,whereasunion 'sonly look atthetoplevel. Thus path compression hasnoeffect onunion operations andleavesthetoplevel unchanged. Wenow know that theranks ofroot nodes areunaltered, butwhat about nonroot nodes? The keypoint here isthat once anode ceases tobearoot, itnever resurfaces ,anditsrank isforever xed. Therefore theranks ofallnodes areunchanged bypath compression, even though these numbers cannolonger beinterpreted astree heights .Inparticular ,properties 1Â–3(from page 145) stillhold. Ifthere arenelements ,their rank values canrange from 0tolognbyProperty 3.Let's divide thenonzero part ofthis range into certain carefully chosen intervals ,forreasons that willsoon become clear: f1g;f2g;f3;4g;f5;6;:::;16g;f17;18;:::;216=65536g;f65537;65538;:::;265536g;::: Eachgroup isoftheformfk+1;k+2;:::;2kg,wherekisapower of2.Thenumber ofgroups islogn,whic hisdened tobethenumber ofsuccessive logoperations that need tobeapplied
5âŒ˜9âŒ˜148 Algorithms Figure 5.7Theeffect ofpath compression: find (I)followed byfind (K). B0 D0 I0J0K0H0C1 1G1A3 FE2 !B0 0D K0J0I0 H0C1F1 G1A3 E2 ! B0 D H0J0I0K0G1C1F1E2A 03 tontobring itdown to1(orbelow 1).Forinstance ,log1000=4since loglogloglog10001. Inpractice there will just betherst veoftheintervals shown; more areneeded only if n265536,inother words never . Inasequence offind operations ,some maytake longer than others .We'llbound the overall running time using some creative accounting .Specically ,wewill give eachnode a certain amount ofpocketmoney ,suchthat thetotal money doled outisatmostnlogndollars . Wewillthen show that eachfind takesO(logn)steps ,plus some additional amount oftime that canbeÂ“paid forÂ”using thepocketmoney ofthenodes involvedÂ—one dollar perunit of time.Thus theoverall time formfind 'sisO(mlogn)plus atmostO(nlogn). Inmore detail, anode receives itsallow ance assoon asitceases tobearoot, atwhic hpoint itsrank isxed. Ifthis rank liesintheintervalfk+1;:::;2kg,thenode receives 2kdollars . ByProperty 3,thenumber ofnodes with rank>kisbounded by n 2k+1+n 2k+2+n 2k: Therefore thetotal money given tonodes inthisparticular interval isatmostndollars ,and since there arelognintervals ,thetotal money disbursed toallnodes isnlogn.
5âŒ˜10âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 149 Now,thetime taken byaspecicfind issimply thenumber ofpointers followed. Consider theascending rank values along thischain ofnodes uptotheroot. Nodesxonthechain fall into twocategories: either therank of(x)isinahigher interval than therank ofx,orelse itliesinthesame interval. There areatmost lognnodes oftherst type (doyouseewhy?), sothework done onthem takesO(logn)time.Theremaining nodesÂ—whose parents' ranks areinthesame interval astheirsÂ—ha vetopayadollar outoftheir pocketmoney fortheir processing time. This only works iftheinitial allow ance ofeachnodexisenough tocover allofitspayments inthesequence offind operations .Here' sthecrucial observation: eachtimexpaysadollar , itsparent changes tooneofhigher rank. Therefore ,ifx'srank liesintheintervalfk+ 1;:::;2kg,ithastopayatmost 2kdollars before itsparent' srank isinahigher interval; whereupon itnever hastopayagain.
5âŒ˜11âŒ˜150 Algorithms Arandomized algorithm forminimum cut Wehavealready seen that spanning trees andcuts areintimately related. Here isanother connection. Let'sremove thelastedge that Kruskal' salgorithm adds tothespanning tree; this breaks thetree into twocomponents ,thus dening acut(S;S)inthegraph. What canwesayabout this cut? Suppose thegraph wewere working with wasunweighted, and that itsedges were ordered uniformly atrandom forKruskal' salgorithm toprocess them. Here isaremarkable fact: with probability atleast 1=n2,(S;S)istheminimum cutinthe graph, where thesizeofacut(S;S)isthenumber ofedges crossing betweenSandS.This means that repeating theprocessO(n2)times andoutputting thesmallest cutfound yields theminimum cutinGwith high probability: anO(mn2logn)algorithm forunweighted minimum cuts.Some further tuning gives theO(n2logn)minimum cutalgorithm, invented byDavidKarger ,whic histhefastest known algorithm forthisimportant problem. Soletusseewhy thecutfound ineachiteration istheminimum cutwith probability at least1=n2.Atanystage ofKruskal' salgorithm, thevertex setVispartitioned intoconnected components .The only edges eligible tobeadded tothetree havetheir twoendpoints in distinct components .The number ofedges incident toeachcomponent must beatleast C,thesize oftheminimum cutinG(since wecould consider acutthat separated this component from therest ofthegraph). Soifthere arekcomponents inthegraph, the number ofeligible edges isatleastkC=2(eachofthekcomponents hasatleastCedges leading outofit,andweneed tocompensate forthedouble-counting ofeachedge). Since the edges were randomly ordered, thechance that thenext eligible edge inthelistisfrom the minimum cutisatmostC=(kC=2)=2=k.Thus ,with probability atleast12=k=(k2)=k, thechoice leavestheminimum cutintact. But now thechance that Kruskal' salgorithm leavestheminimum cutintact allthewayuptothechoice ofthelastspanning tree edge is atleastn2 nn3 n1n4 n22 41 3=1 n(n1): 5.1.5 Prim' salgorithm Let'sreturn toourdiscussion ofminimum spanning tree algorithms .What thecutproperty tells usinmost general terms isthat anyalgorithm conforming tothefollowing greedy schema isguaranteed towork. X=fg(edgespickedsofar) repeatuntiljXj=jVj1: pickasetSVforwhichXhasnoedgesbetweenSandVS lete2Ebetheminimum-weight edgebetweenSandVS X=X[feg Apopular alternative toKruskal' salgorithm isPrim' s,inwhic htheintermediate setofedges Xalwaysforms asubtree ,andSischosen tobethesetofthistree'svertices . Oneachiteration, thesubtree dened byXgrows byoneedge,namely ,thelightest edge between avertex inSandavertex outsideS(Figure 5.8). Wecanequivalently think ofSas
5âŒ˜12âŒ˜"S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 151 Figure 5.8Prim' salgorithm: theedgesXform atree,andSconsists ofitsvertices .               ! ! "" "" "" ""# # # #$ $% %eS VS X growing toinclude thevertexv62Sofsmallestcost : cost(v)=min u2Sw(u;v): This isstrongly reminiscent ofDijkstra' salgorithm, andinfactthepseudocode (Figure 5.9) isalmost identical. The only difference isinthekeyvalues bywhic hthepriority queue is ordered. InPrim' salgorithm, thevalue ofanode istheweight ofthelightest incoming edge from setS,whereas inDijkstra' sitisthelength ofanentire path tothat node from the starting point. Nonetheless ,thetwoalgorithms aresimilar enough that they havethesame running time,whic hdepends ontheparticular priority queue implementation. Figure 5.9shows Prim' salgorithm atwork, onasmall six-node graph. Notice how the nal MST iscompletely specied bytheprev array."
5âŒ˜13âŒ˜152 Algorithms Figure 5.9Top:Prim' sminimum spanning tree algorithm. Below: Anillustration ofPrim' s algorithm, starting atnodeA.Also shown areatable ofcost /prev values ,andthenal MST . procedure prim(G;w) Input: Aconnected undirected graphG=(V;E)withedgeweightswe Output: Aminimum spanning treedefined bythearrayprev forallu2V: cost(u)=1 prev(u)=nil Pickanyinitial nodeu0 cost(u0)=0 H=makequeue (V)(priority queue,usingcost-values askeys) whileHisnotempty: v=deletemin (H) foreachfv;zg2E: ifcost(z)>w(v;z): cost(z)=w(v;z) prev(z)=v decreasekey (H;z) BA6 5 3 4 2F DC E 5 4124 BA F DC E SetSABCDEF fg 0=nil1=nil1=nil1=nil1=nil1=nil A 5=A 6=A 4=A1=nil1=nil A;D 2=D 2=D1=nil 4=D A;D;B 1=B1=nil 4=D A;D;B;C 5=C 3=C A;D;B;C;F 4=F
5âŒ˜14âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 153 5.2 Huffman encoding IntheMP3 audio compression scheme ,asound signal isencoded inthree steps . 1.Itisdigitized bysampling atregular intervals ,yielding asequence ofreal numbers s1;s2;:::;sT.Forinstance ,atarate of44;100samples persecond, a50-minute symphony would correspond toT=506044;100130million measurements .1 2.Eachreal-valued samplestisquantized :approximated byanearby number from a nite set.This setiscarefully chosen toexploit human perceptual limitations ,with theintention that theapproximating sequence isindistinguishable froms1;s2;:::;sTby thehuman ear. 3.Theresulting string oflengthTover alphabet isencoded inbinary . Itisinthelaststep that Huffman encoding isused. Tounderstand itsrole,let'slook atatoy example inwhic hTis130million andthealphabet consists ofjustfour values ,denoted by thesymbolsA;B;C;D.What isthemost economical waytowrite this long string inbinary? The obvious choice istouse2bits persymbolÂ—sa ycodeword 00forA,01forB,10forC, and11forDÂ—in whic hcase260megabits areneeded intotal. Can there possibly beabetter encoding than this? Insearc hofinspiration, wetake acloser look atourparticular sequence andndthat the four symbols arenotequally abundant. Symbol Frequency A 70million B 3million C 20million D 37million Isthere some sortofvariable-length encoding ,inwhic hjustonebitisused forthefrequently occurring symbolA,possibly attheexpense ofneeding three ormore bits forless common symbols? Adanger with having codewords ofdifferent lengths isthat theresulting encoding may notbeuniquely decipherable .Forinstance ,ifthecodewords aref0;01;11;001g,thedecoding ofstrings like001isambiguous .Wewill avoid this problem byinsisting ontheprex-free property: nocodeword canbeaprex ofanother codeword. Any prex-free encoding canberepresented byafullbinary treeÂ—that is,abinary tree in whic hevery node haseither zero ortwochildrenÂ—where thesymbols areattheleaves,and where eachcodeword isgenerated byapath from root toleaf,interpreting leftas0andright as1(Exercise 5.28). Figure 5.10 shows anexample ofsuchanencoding forthefour symbols A;B;C;D.Decoding isunique: astring ofbitsisdecrypted bystarting attheroot, reading thestring from lefttoright tomove downw ard, and, whenever aleafisreached, outputting thecorresponding symbol andreturning totheroot. Itisasimple scheme andpaysoffnicely 1Forstereo sound, twochannels would beneeded, doubling thenumber ofsamples .
5âŒ˜15âŒ˜154 Algorithms Figure 5.10 Aprex-free encoding .Frequencies areshown insquare brackets. Symbol Codeword A 0 B 100 C 101 D 110 A[70]1 [60] C[20] B[3]D[37][23] forourtoyexample ,where (under thecodes ofFigure 5.10) thetotal sizeofthebinary string drops to213megabits ,a17% improvement. Ingeneral, how dowend theoptimal coding tree,given thefrequencies f1;f2;:::;fnof nsymbols? Tomake theproblem precise ,wewantatree whose leaveseachcorrespond toa symbol andwhic hminimizes theoverall length oftheencoding , costoftree =nX i=1fi(depth ofithsymbol intree) (the number ofbitsrequired forasymbol isexactly itsdepth inthetree). There isanother waytowrite thiscostfunction that isvery helpful. Although weareonly given frequencies fortheleaves,wecandene thefrequency ofanyinternal node tobethe sum ofthefrequencies ofitsdescendant leaves; this is,after all,thenumber oftimes the internal node isvisited during encoding ordecoding .During theencoding process ,eachtime wemove down thetree,onebitgets output forevery nonroot node through whic hwepass.So thetotal costÂ—the total number ofbitswhic hareoutputÂ—can also beexpressed thus: The cost ofatree isthesum ofthefrequencies ofallleavesand internal nodes , except theroot. The rst formulation ofthecost function tells usthat thetwosymbols with thesmallest frequencies must beatthebottom oftheoptimal tree,aschildren ofthelowest internal node (this internal node hastwochildren since thetree isfull).Otherwise ,swapping these two symbols with whatever islowest inthetree would improve theencoding . This suggests that westart constructing thetree greedil y:nd thetwosymbols with the smallest frequencies ,sayiandj,and make them children ofanew node ,whic hthen has frequencyfi+fj.Tokeep thenotation simple ,let'sjustassume these aref1andf2.Bythe second formulation ofthecostfunction, anytree inwhic hf1andf2aresibling-lea veshascost f1+f2plus thecostforatree withn1leavesoffrequencies (f1+f2);f3;f4;:::;fn:
5âŒ˜16âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 155 f1 f2f3 f5 f4f1+f2 The latter problem isjustasmaller version oftheonewestarted with. Sowepullf1andf2 offthelistoffrequencies ,insert (f1+f2),andloop.Theresulting algorithm canbedescribed interms ofpriority queue operations (asdened onpage 120) andtakesO(nlogn)time ifa binary heap (Section 4.5.2) isused. procedure Huffman(f) Input: Anarrayf[1n]offrequencies Output: Anencoding treewithnleaves letHbeapriority queueofintegers, ordered byf fori=1ton:insert(H;i) fork=n+1to2n1: i=deletemin (H);j=deletemin (H) createanodenumbered kwithchildren i;j f[k]=f[i]+f[j] insert (H;k) Returning toourtoyexample: canyoutellifthetree ofFigure 5.10 isoptimal?
5âŒ˜17âŒ˜156 Algorithms Entropy Theannual county horse race isbringing inthree thoroughbreds who havenever competed against oneanother .Excited, youstudy their past 200races andsummarize these asprob- ability distributions over four outcomes: first (Â“rst placeÂ”),second ,third ,andother . Outcome Aurora Whirlwind Phantasm first 0.15 0.30 0.20 second 0.10 0.05 0.30 third 0.70 0.25 0.30 other 0.05 0.40 0.20 Whic hhorse isthemost predictable? One quantitative approac htothis question is tolook atcompressibility .Write down thehistory ofeachhorse asastring of200values (first ,second ,third ,other ).The total number ofbits needed toencode these track- record strings canthen becomputed using Huffman' salgorithm. This works outto290bits forAurora, 380forWhirlwind, and 420forPhantasm (checkit!). Aurora hastheshortest encoding andistherefore inastrong sense themost predictable . The inherent unpredictability ,orrandomness ,ofaprobability distribution canbemea- sured bytheextent towhic hitispossible tocompress data drawnfrom that distribution. more compressiblelessrandommore predictable Suppose there arenpossible outcomes ,with probabilities p1;p2;:::;pn.Ifasequence ofm values isdrawnfrom thedistribution, then theithoutcome willpopuproughlympitimes (if mislarge). Forsimplicity ,assume these areexactly theobserved frequencies ,andmoreover that thepi'sareallpowers of2(that is,oftheform 1=2k).Itcanbeseen byinduction (Exercise 5.19) that thenumber ofbitsneeded toencode thesequence isPn i=1mpilog(1=pi). Thus theaverage number ofbitsneeded toencode asingle drawfrom thedistribution is nX i=1pilog1 pi: This istheentropy ofthedistribution, ameasure ofhow muchrandomness itcontains . Forexample ,afaircoin hastwooutcomes ,eachwith probability 1=2.Soitsentropy is 1 2log2+1 2log2=1: This isnatural enough: thecoin ipcontains onebitofrandomness .Butwhat ifthecoin is notfair,ifithasa3=4chance ofturning upheads? Then theentropy is 3 4log4 3+1 4log4=0:81: Abiased coin ismore predictable than afaircoin, andthus haslower entropy .Asthebias becomes more pronounced, theentropy drops towardzero. Weexplore these notions further inExercise 5.18 and5.19.
5âŒ˜18âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 157 5.3 Horn formulas Inorder todispla yhuman-level intelligence ,acomputer must beable toperform atleast some modicum oflogical reasoning .Horn formulas areaparticular framework fordoing this,for expressing logical facts andderiving conclusions . The most primitive object inaHorn formula isaBoolean variable ,taking value either true orfalse .Forinstance ,variablesx,y,andzmight denote thefollowing possibilities . xthemurder took place inthekitchen ythebutler isinnocent zthecolonel wasasleep at8pm Aliteral iseither avariablexoritsnegationx(Â“NOTxÂ”).InHorn formulas ,knowledge about variables isrepresented bytwokinds ofclauses : 1.Implications ,whose left-hand sideisanANDofanynumber ofpositive literals andwhose right-hand side isasingle positive literal. These express statements oftheform Â“ifthe conditions onthelefthold, then theoneontheright must also betrue.Â”Forinstance , (z^w))u might mean Â“ifthecolonel wasasleep at8pmandthemurder took place at8pmthen thecolonel isinnocent. Â”Adegenerate type ofimplication isthesingleton Â“)x,Â”meaning simply thatxistrue :Â“the murder denitely occurred inthekitchen.Â” 2.Pure negative clauses ,consisting ofanORofanynumber ofnegative literals ,asin (u_v_y) (Â“they can't allbeinnocentÂ”). Given asetofclauses ofthese twotypes ,thegoal istodetermine whether there isaconsis- tent explanation: anassignment oftrue /false values tothevariables that satises allthe clauses .This isalso called asatisfying assignment . The twokinds ofclauses pull usindifferent directions .The implications tellustoset some ofthevariables totrue ,while thenegative clauses encourage ustomake themfalse . Our strategy forsolving aHorn formula isthis: Westart with allvariables false .Wethen proceed tosetsome ofthem totrue ,onebyone,butvery reluctantly ,andonly ifweabsolutely havetobecause animplication would otherwise beviolated. Once wearedone with thisphase andallimplications aresatised, only then doweturn tothenegative clauses andmake sure they areallsatised. Inother words ,ouralgorithm forHorn clauses isthefollowing greedy scheme (stingy is perhaps more descriptive): Input: aHornformula Output: asatisfying assignment, ifoneexists
5âŒ˜19âŒ˜158 Algorithms setallvariables tofalse whilethereisanimplication thatisnotsatisfied: settheright-hand variable oftheimplication totrue ifallpurenegative clauses aresatisfied: returntheassignment else:return``formula isnotsatisfiable'' Forinstance ,suppose theformula is (w^y^z))x;(x^z))w;x)y;)x;(x^y))w;(w_x_y);(z): Westart with everything false andthen notice thatxmust betrue onaccount ofthesin- gleton implication)x.Then weseethatymust also betrue ,because ofx)y.And so on. Toseewhy thealgorithm iscorrect, notice that ifitreturns anassignment, this assign- ment satises both theimplications andthenegative clauses ,andsoitisindeed asatisfying truth assignment oftheinput Horn formula. Soweonly havetoconvince ourselves that if thealgorithm nds nosatisfying assignment, then there really isnone .This issobecause our Â“stingyÂ” rule maintains thefollowing invariant: Ifacertain setofvariables issettotrue ,then they must betrue inanysatisfying assignment. Hence ,ifthetruth assignment found after thewhile loop does notsatisfy thenegative clauses , there canbenosatisfying truth assignment. Horn formulas lieattheheart ofProlog (Â“programming bylogicÂ”), alanguage inwhic hyou program byspecifying desired properties oftheoutput, using simple logical expressions .The workhorse ofProlog interpreters isourgreedy satisability algorithm. Conveniently ,itcan beimplemented intime linear inthelength oftheformula; doyouseehow (Exercise 5.32)? 5.4 Setcover The dots inFigure 5.11 represent acollection oftowns .This county isinitsearly stages of planning and isdeciding where toputschools .There areonly twoconstraints: eachschool should beinatown, andnooneshould havetotravelmore than30miles toreachoneofthem. What istheminimum number ofschools needed? This isatypical setcover problem. Foreachtownx,letSxbethesetoftowns within 30 miles ofit.Aschool atxwillessentially Â“coverÂ” these other towns .Thequestion isthen, how many setsSxmust bepickedinorder tocover allthetowns inthecounty? SETCOVER Input: AsetofelementsB;setsS1;:::;SmB
5âŒ˜20âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 159 Figure 5.11 (a)Eleven towns .(b)Towns that arewithin 30miles ofeachother . (a) hb k jigf eac d(b) hb k jigf eac d Output: Aselection oftheSiwhose union isB. Cost: Number ofsets picked. (Inourexample ,theelements ofBarethetowns .)This problem lends itself immediately toa greedy solution: Repeat until allelements ofBarecovered: PickthesetSiwith thelargest number ofuncovered elements . This isextremely natural and intuitive .Let'sseewhat itwould doonourearlier example: Itwould rst place aschool attowna,since this covers thelargest number ofother towns . Thereafter ,itwould choose three more schoolsÂ—c,j,and eitherforgÂ—for atotal offour. However ,there exists asolution with justthree schools ,atb,e,andi.The greedy scheme is notoptimal! Butluckily,itisn't toofarfrom optimal. Claim SupposeBcontainsnelements andthat theoptimal cover consists ofksets.Then the greedy algorithm willuseatmostklnnsets.2 Letntbethenumber ofelements stillnotcovered aftertiterations ofthegreedy algorithm (son0=n).Since these remaining elements arecovered bytheoptimalksets,there must be some setwith atleastnt=kofthem. Therefore ,thegreedy strategy willensure that nt+1ntnt k=nt 11 k ; whic hbyrepeated application impliesntn0(11=k)t.Amore convenient bound canbe obtained from theuseful inequality 1xexforallx,with equality ifandonly ifx=0, 2lnmeans Â“natural logarithm, Â”that is,tothebasee.
5âŒ˜21âŒ˜160 Algorithms whic hismost easily proved byapicture: x011xex Thus ntn0 11 kt <n0(e1=k)t=net=k: Att=klnn,therefore ,ntisstrictly lessthannelnn=1,whic hmeans noelements remain to becovered. The ratio between thegreedy algorithm' ssolution and theoptimal solution varies from input toinput butisalwayslessthanlnn.And there arecertain inputs forwhic htheratio is very closetolnn(Exercise 5.33). Wecallthismaximum ratio theapproximation factor ofthe greedy algorithm. There seems tobealotofroom forimprovement, butinfactsuchhopes are unjustied: itturns outthat under certain widely-held complexity assumptions (whic hwill beclearer when wereachChapter 8),there isprovably nopolynomial-time algorithm with a smaller approximation factor .
5âŒ˜22âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 161 Exercises 5.1. Consider thefollowing graph. A B C D E F G H1 2 2 16 5 6 3 354 5 7 (a)What isthecostofitsminimum spanning tree? (b)How many minimum spanning trees does ithave? (c)Suppose Kruskal' salgorithm isrunonthisgraph. Inwhat order aretheedges added tothe MST? Foreachedge inthissequence ,give acutthat justies itsaddition. 5.2. Suppose wewanttondtheminimum spanning tree ofthefollowing graph. A B C D E F G H1 2 412 68 56 4 1 13 (a)Run Prim' salgorithm; whenever there isachoice ofnodes ,alwaysusealphabetic ordering (e.g.,start from nodeA).Drawatable showing theintermediate values ofthecost array. (b)Run Kruskal' salgorithm onthesame graph. Show how thedisjoint-sets data structure looks atevery intermediate stage (including thestructure ofthedirected trees), assuming path compression isused. 5.3. Design alinear -time algorithm forthefollowing task. Input: Aconnected, undirected graphG. Question: Isthere anedge youcanremove fromGwhile stillleavingGconnected? Can youreduce therunning time ofyour algorithm toO(jVj)? 5.4. Show that ifanundirected graph withnvertices haskconnected components ,then ithasat leastnkedges . 5.5. Consider anundirected graphG=(V;E)with nonnegative edge weightswe0.Suppose that youhavecomputed aminimum spanning tree ofG,andthat youhavealso computed shortest paths toallnodes from aparticular nodes2V. Now suppose eachedge weight isincreased by1:thenew weights arew0 e=we+1. (a)Does theminimum spanning tree change? Give anexample where itchanges orprove it cannot change . (b)Dotheshortest paths change? Give anexample where they change orprove they cannot change .
5âŒ˜23âŒ˜162 Algorithms 5.6. LetG=(V;E)beanundirected graph. Prove that ifallitsedge weights aredistinct, then ithas aunique minimum spanning tree. 5.7. Show how tond themaximum spanning tree ofagraph, that is,thespanning tree oflargest total weight. 5.8. Suppose youaregiven aweighted graphG=(V;E)with adistinguished vertexsand where alledge weights arepositive anddistinct. Isitpossible foratree ofshortest paths fromsand aminimum spanning tree inGtonotshare anyedges? Ifso,give anexample .Ifnot, give a reason. 5.9. The following statements mayormaynotbecorrect. Ineachcase,either prove it(ifitiscor- rect) orgive acounterexample (ifitisn't correct). Alwaysassume that thegraphG=(V;E)is undirected. Donotassume that edge weights aredistinct unless thisisspecically stated. (a)IfgraphGhasmore thanjVj1edges ,andthere isaunique heaviest edge ,then thisedge cannot bepart ofaminimum spanning tree. (b)IfGhasacyclewith aunique heaviest edgee,thenecannot bepart ofanyMST . (c)Letebeanyedge ofminimum weight inG.Thenemust bepart ofsome MST . (d)Ifthelightest edge inagraph isunique ,then itmust bepart ofevery MST . (e)Ifeispart ofsome MST ofG,then itmust bealightest edge across some cutofG. (f)IfGhasacyclewith aunique lightest edgee,thenemust bepart ofevery MST . (g)Theshortest-path tree computed byDijkstra' salgorithm isnecessarily anMST . (h)Theshortest path between twonodes isnecessarily part ofsome MST . (i)Prim' salgorithm works correctly when there arenegative edges . (j)(Foranyr>0,dene anr-path tobeapath whose edges allhaveweight<r.)IfGcontains anr-path from nodestot,then every MST ofGmust also contain anr-path from nodesto nodet. 5.10. LetTbeanMST ofgraphG.Given aconnected subgraphHofG,show thatT\Hiscontained insome MST ofH. 5.11. Give thestate ofthedisjoint-sets data structure after thefollowing sequence ofoperations ,start- ingfrom singleton setsf1g;:::;f8g.Usepath compression. Incase ofties,alwaysmake thelower numbered root point tothehigher numbered one. union (1;2);union (3;4);union (5;6);union (7;8);union (1;4);union (6;7);union (4;5);find(1) 5.12. Suppose youimplement thedisjoint-sets data structure using union-by-rank butnotpath com- pression. Give asequence ofmunion andfind operations onnelements that take (mlogn) time. 5.13. Along string consists ofthefour charactersA;C;G;T;they appear with frequency 31%;20%;9%, and40%,respectively .What istheHuffman encoding ofthese four characters? 5.14. Suppose thesymbolsa;b;c;d;eoccur with frequencies 1=2;1=4;1=8;1=16;1=16,respectively . (a)What istheHuffman encoding ofthealphabet? (b)Ifthisencoding isapplied toaleconsisting of1;000;000characters with thegiven frequen- cies,what isthelength oftheencoded leinbits?
5âŒ˜24âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 163 5.15. WeuseHuffman' salgorithm toobtain anencoding ofalphabetfa;b;cgwith frequencies fa;fb;fc. Ineachofthefollowing cases ,either give anexample offrequencies (fa;fb;fc)that would yield thespecied code,orexplain why thecode cannot possibly beobtained (nomatter what the frequencies are). (a)Code:f0;10;11g (b)Code:f0;1;00g (c)Code:f10;01;00g 5.16. Prove thefollowing twoproperties oftheHuffman encoding scheme . (a)Ifsome character occurs with frequency more than 2=5,then there isguaranteed tobea codeword oflength 1. (b)Ifallcharacters occur with frequency less than 1=3,then there isguaranteed tobeno codeword oflength 1. 5.17. Under aHuffman encoding ofnsymbols with frequencies f1;f2;:::;fn,what isthelongest a codeword could possibly be?Give anexample setoffrequencies that would produce thiscase. 5.18. The following table gives thefrequencies oftheletters oftheEnglish language (including the blank forseparating words) inaparticular corpus . blank 18.3% r4.8% y1.6% e 10.2% d3.5% p1.6% t 7.7% l3.4% b1.3% a 6.8% c2.6% v0.9% o 5.9% u2.4% k0.6% i 5.8% m 2.1% j0.2% n 5.5% w1.9% x0.2% s 5.1% f1.8% q0.1% h 4.9% g1.7% z0.1% (a)What istheoptimum Huffman encoding ofthisalphabet? (b)What istheexpected number ofbitsperletter? (c)Suppose now that wecalculate theentropy ofthese frequencies H=26X i=0pilog1 pi (see theboxinpage 156). Would youexpect ittobelarger orsmaller than your answer above? Explain. (d)Doyouthink that this isthelimit ofhow muchEnglish text canbecompressed? What features oftheEnglish language ,besides letters and their frequencies ,should abetter compression scheme take into account? 5.19. Entropy .Consider adistribution overnpossible outcomes ,with probabilities p1;p2;:::;pn.
5âŒ˜25âŒ˜164 Algorithms (a)Justforthis part oftheproblem, assume that eachpiisapower of2(that is,oftheform 1=2k).Suppose along sequence ofmsamples isdrawnfrom thedistribution andthat forall 1in,theithoutcome occurs exactlympitimes inthesequence .Show that ifHuffman encoding isapplied tothissequence ,theresulting encoding willhavelength nX i=1mpilog1 pi: (b)Now consider arbitrary distributionsÂ—that is,theprobabilities piarenotrestricted topow- ersof2.Themost commonly used measure oftheamount ofrandomness inthedistribution istheentropy nX i=1pilog1 pi: Forwhat distribution (overnoutcomes) istheentropy thelargest possible? The smallest possible? 5.20. Give alinear -time algorithm that takes asinput atree anddetermines whether ithasaperfect matc hing :asetofedges that toucheseachnode exactly once. Afeedbac kedge setofanundirected graphG=(V;E)isasubset ofedgesE0Ethat intersects every cycleofthegraph. Thus ,removing theedgesE0willrender thegraph acyclic. Give anefcient algorithm forthefollowing problem: Input: Undirected graphG=(V;E)with positive edge weightswe Output: Afeedbac kedge setE0Eofminimum total weightP e2E0we 5.21. Inthisproblem, wewilldevelop anew algorithm fornding minimum spanning trees .Itisbased upon thefollowing property: Pickanycycleinthegraph, andletebetheheaviest edge inthat cycle.Then there is aminimum spanning tree that does notcontaine. (a)Prove thisproperty carefully . (b)Here isthenew MST algorithm. The input issome undirected graphG=(V;E)(inadja- cency listformat) with edge weightsfweg. sorttheedgesaccording totheirweights foreachedgee2E,indecreasing orderofwe: ifeispartofacycleofG: G=Ge(thatis,removeefromG) returnG Prove that thisalgorithm iscorrect. (c)Oneachiteration, thealgorithm must checkwhether there isacyclecontaining aspecic edgee.Give alinear -time algorithm forthistask, andjustify itscorrectness . (d)What istheoverall time taken bythisalgorithm, interms ofjEj?Explain your answer .
5âŒ˜26âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 165 5.22. Youaregiven agraphG=(V;E)with positive edge weights ,and aminimum spanning tree T=(V;E0)with respect tothese weights; youmayassumeGandTaregiven asadjacency lists. Now suppose theweight ofaparticular edgee2Eismodied fromw(e)toanew value ^w(e).You wish toquicklyupdate theminimum spanning treeTtoreect thischange ,without recomputing theentire tree from scratc h.There arefour cases .Ineachcase give alinear -time algorithm for updating thetree. (a)e62E0and^w(e)>w(e). (b)e62E0and^w(e)<w(e). (c)e2E0and^w(e)<w(e). (d)e2E0and^w(e)>w(e). 5.23. Sometimes wewantlight spanning trees with certain special properties .Here' sanexample . Input: Undirected graphG=(V;E);edge weightswe;subset ofverticesUV Output: Thelightest spanning tree inwhic hthenodes ofUareleaves (there might be other leavesinthistree aswell). (The answer isn't necessarily aminimum spanning tree.) Give analgorithm forthis problem whic hruns inO(jEjlogjVj)time.(Hint: When youremove nodesUfrom theoptimal solution, what isleft?) 5.24. Abinary counter ofunspecied length supports twooperations: increment (whic hincreases its value byone) andreset (whic hsetsitsvalue backtozero). Show that, starting from aninitially zero counter ,anysequence ofnincrement andreset operations takes timeO(n);that is,the amortized time peroperation isO(1). 5.25. Here' saproblem that occurs inautomatic program analysis .Forasetofvariablesx1;:::;xn, youaregiven some equality constraints ,oftheform Â“xi=xjÂ”andsome disequality constraints , oftheform Â“xi6=xj.Â”Isitpossible tosatisfy allofthem? Forinstance ,theconstraints x1=x2;x2=x3;x3=x4;x16=x4 cannot besatised. Give anefcient algorithm that takes asinputmconstraints overnvariables anddecides whether theconstraints canbesatised. 5.26. Graphs with prescribed degree sequences .Given alistofnpositive integersd1;d2;:::;dn,wewant toefciently determine whether there exists anundirected graphG=(V;E)whose nodes have degrees preciselyd1;d2;:::;dn.That is,ifV=fv1;:::;vng,then thedegree ofvishould beexactly di.Wecall(d1;:::;dn)thedegree sequence ofG.This graphGshould notcontain self-loops (edges with both endpoints equal tothesame node) ormultiple edges between thesame pair ofnodes . (a)Give anexample ofd1;d2;d3;d4where allthedi3andd1+d2+d3+d4iseven, butfor whic hnograph with degree sequence (d1;d2;d3;d4)exists . (b)Suppose thatd1d2dnand that there exists agraphG=(V;E)with degree sequence (d1;:::;dn).Wewanttoshow that there must exist agraph that hasthisdegree sequence and where inaddition theneighbors ofv1arev2;v3;:::;vd1+1.The idea isto gradually transform Ginto agraph with thedesired additional property . i.Suppose theneighbors ofv1inGarenotv2;v3;:::;vd1+1.Show that there existsi< jnandu2Vsuchthatfv1;vig;fu;vjg=2Eandfv1;vjg;fu;vig2E.
5âŒ˜27âŒ˜166 Algorithms ii.Specify thechanges youwould make toGtoobtain anew graphG0=(V;E0)with the same degree sequence asGandwhere (v1;vi)2E0. iii.Now show that there must beagraph with thegiven degree sequence butinwhic hv1 hasneighborsv2;v3;:::;vd1+1. (c)Using theresult from part (b),describe analgorithm that oninputd1;:::;dn(not necessar - ilysorted) decides whether there exists agraph with thisdegree sequence .Youralgorithm should runintime polynomial innandinm=Pn i=1di. 5.27. Alice wants tothrow aparty andisdeciding whom tocall. Shehasnpeople tochoose from, and shehasmade upalistofwhic hpairs ofthese people know eachother .Shewants topickasmany people aspossible ,subject totwoconstraints: attheparty ,eachperson should haveatleast ve other people whom they know andveother people whom they don't know . Give anefcient algorithm that takes asinput thelistofnpeople andthelistofpairs who know eachother andoutputs thebest choice ofparty invitees .Give therunning time interms ofn. 5.28. Aprex-free encoding ofanite alphabet assigns eachsymbol inabinary codeword, such that nocodeword isaprex ofanother codeword. Show that suchanencoding canberepresented byafullbinary tree inwhic heachleafcorre- sponds toaunique element of,whose codeword isgenerated bythepath from theroot tothat leaf(interpreting aleftbranc has0andaright branc has1). 5.29. Ternary Huffman. Trimedia Disks Inc.hasdeveloped Â“ternaryÂ” hard disks .Eachcellonadisk cannow store values 0,1,or2(instead ofjust0or1).Totake advantage ofthisnew technology , provide amodied Huffman algorithm forcompressing sequences ofcharacters from analpha- betofsizen,where thecharacters occur with known frequencies f1;f2;:::;fn.Youralgorithm should encode eachcharacter with avariable-length codeword over thevalues 0;1;2suchthat no codeword isaprex ofanother codeword andsoastoobtain themaximum possible compression. Prove that your algorithm iscorrect. 5.30. The basic intuition behind Huffman' salgorithm, that frequent blocksshould haveshort en- codings and infrequent blocksshould havelong encodings ,isalso atwork inEnglish, where typical words likeI,you,is,and,to,from ,and soonareshort, and rarely used words like velociraptor arelonger . However ,words likefire! ,help! ,andrun! areshort notbecause they arefrequent, but perhaps because time isprecious insituations where they areused. Tomake things theoretical, suppose wehavealecomposed ofmdifferent words ,with frequen- ciesf1;:::;fm.Suppose also that fortheithword, thecost perbitofencoding isci.Thus ,ifwe nd aprex-free code where theithword hasacodeword oflengthli,then thetotal cost ofthe encoding willbeP ificili. Show how tomodify Huffman' salgorithm tondtheprex-free encoding ofminimum total cost. 5.31. Aserver hasncustomers waiting tobeserved. The service time required byeachcustomer is known inadvance: itistiminutes forcustomeri.Soif,forexample ,thecustomers areserved in order ofincreasing i,then theithcustomer hastowaitPi j=1tjminutes . Wewish tominimize thetotal waiting time T=nX i=1(time spent waiting bycustomeri): Give anefcient algorithm forcomputing theoptimal order inwhic htoprocess thecustomers .
5âŒ˜28âŒ˜S.Dasgupta, C.H.Papadimitriou, andU.V.Vazirani 167 5.32. Show how toimplement thestingy algorithm forHorn formula satisability (Section 5.3)intime that islinear inthelength oftheformula (thenumber ofoccurrences ofliterals init).(Hint: Use adirected graph, with onenode pervariable ,torepresent theimplications .) 5.33. Show that foranyintegernthat isapower of2,there isaninstance ofthesetcover problem (Section 5.4)with thefollowing properties: i.There arenelements inthebase set. ii.Theoptimal cover uses justtwosets. iii.Thegreedy algorithm picksatleast lognsets. Thus theapproximation ratio wederived inthechapter istight.
